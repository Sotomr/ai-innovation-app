import os
import json
import time
import concurrent.futures
import traceback
import time
from datetime import datetime
import random
import urllib.parse
from typing import List, Dict, Any, Optional, Tuple, Union
import re
import tempfile
import unicodedata
from urllib.parse import urlsplit
import requests
from bs4 import BeautifulSoup
import uuid
import PyPDF2
import spacy
import subprocess
import pprint
import hashlib
import functools
import dotenv
from sentence_transformers import SentenceTransformer, util
dotenv.load_dotenv()

# Importaciones de LangChain actualizadas
from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain_text_splitters import RecursiveCharacterTextSplitter
# Importar AzureChatOpenAI desde langchain_openai en lugar de langchain.chat_models
from langchain_openai import AzureChatOpenAI
# Importar DuckDuckGo para b√∫squeda web
from langchain_community.utilities import DuckDuckGoSearchAPIWrapper

# Importaciones para OpenAI directo
from openai import OpenAI, AzureOpenAI
from openai_config import get_openai_client, get_deployment_name

# Configuraci√≥n global para forzar response_format en formato JSON
JSON_RESPONSE_FORMAT = {"type": "json_object"}
# Temperatura m√°s baja para respuestas determin√≠sticas en JSON
SAFE_TEMPERATURE = 0.0

# Cliente de OpenAI para uso directo
client = get_openai_client()
DEPLOYMENT_NAME = get_deployment_name()

# Importar el nuevo m√≥dulo de PDF
from competition_pdf_module import generate_competition_analysis_pdf, generate_professional_report_pdf

# Importar langchain_tavily y tavily_config
from langchain_tavily import TavilySearch
from tavily_config import get_tavily_api_key, set_tavily_api_key

from llm_utils import get_llm_keywords

from query_generator import generate_queries

# --- Carga robusta de Spacy ---
try:
    nlp = spacy.load("es_core_news_sm")
except Exception as e:
    print(f"‚ö†Ô∏è No se pudo cargar 'es_core_news_sm': {e}. Usando modelo en blanco.")
    nlp = spacy.blank("es")

STOPWORDS = {"el","la","los","las","de","del","para","con","un","una","en","por","que","y"}

# --- SECTION_SCHEMAS global inmutable para AI-only ---
SECTION_SCHEMAS = {
    'COMPETITOR_MAPPING': '{"competidores_directos":[],"competidores_indirectos":[],"emergentes":[]}',
    'BENCHMARK_MATRIX': '{"tabla_comparativa":[{"nombre":"","ingresos_anuales_millones_eur":0,"empleados_total":0,"a√±os_en_mercado":0,"paises_presencia":0,"proyectos_anuales_estimados":0,"precio_promedio_proyecto_millones":0,"cuota_mercado_sector_porcentaje":0,"gasto_id_porcentaje_ingresos":0,"certificaciones_principales":0,"patentes_activas_estimadas":0}],"metricas_comparativas":{"lider_ingresos":{"empresa":"","valor":0},"lider_empleados":{"empresa":"","valor":0},"lider_cuota_mercado":{"empresa":"","valor":0},"promedio_sector_ingresos":0,"promedio_sector_empleados":0},"gaps_cuantitativos":[{"metrica":"","brecha_identificada":"","oportunidad_sener":""}]}',
    'TECH_IP_LANDSCAPE': '{"patentes_destacadas":[{"titulo":"","numero_patente":"","titular":"","a√±o":"","pais":"","descripcion":"","relevancia_competitiva":"","url":""}],"publicaciones_clave":[{"titulo":"","autores":"","revista":"","a√±o":"","tipo":"","resumen":"","relevancia_tecnologica":"","url":""}],"gaps_tecnologicos":[{"area_tecnologica":"","descripcion_gap":"","impacto_competitivo":"","oportunidad_sener":""}],"tendencias_emergentes":[{"tecnologia":"","estado_madurez":"","potencial_disruptivo":"","plazo_adopcion":""}]}',
    'MARKET_ANALYSIS': '{"TAM_2025":0,"CAGR_2025_2030":0,"segmentos":[],"geografias":[],"drivers":[],"restrictores":[],"analisis_cualitativo":{"gaps_identificados":[],"oportunidades_sener":[]}}',
    'SWOT_POSITIONING': '{"swot":{"fortalezas":[],"debilidades":[],"oportunidades":[],"amenazas":[]},"mapa_posicionamiento":{"eje_x":"","eje_y":"","comentario":""}}',
    'REGULATORY_ESG_RISK': '{"normativas_clave":[],"certificaciones":[],"riesgos":[],"oportunidades_ESG":[]}',
    'STRATEGIC_ROADMAP': '{"acciones_90_dias":[],"acciones_12_meses":[],"acciones_36_meses":[],"KPIs_clave":[]}',
    'APPENDIX': '{"glosario":{},"metodologia":"","limitaciones":""}',
    'EXEC_SUMMARY': '{"resumen":"","bullets":[]}'
}

def _extract_keywords(text: str, k: int = 3) -> str:
    """Devuelve ‚â§k lemas relevantes (NOUN, PROPN, ADJ)."""
    doc = nlp(text[:120])  # analiza solo la 1.¬™ frase
    tokens = [t.lemma_.lower() for t in doc
              if t.pos_ in {"NOUN", "PROPN", "ADJ"}
              and len(t) > 3
              and t.lemma_.lower() not in STOPWORDS]
    seen, kw = set(), []
    for tok in tokens:
        if tok not in seen:
            seen.add(tok)
            kw.append(tok)
        if len(kw) == k:
            break
    return " ".join(kw) if kw else " ".join(text.split()[:k])

def extract_json_block(text):
    """
    Extrae el primer bloque JSON v√°lido de un texto, incluso si est√° dentro de un bloque de c√≥digo.
    Intenta limpiar y reparar el JSON si est√° malformado, incluyendo la inserci√≥n de comas faltantes entre pares clave-valor.
    """
    import re, json, os, traceback
    
    # Validar tipo de entrada
    if text is None:
        raise ValueError("El texto de entrada es None")
    
    if not isinstance(text, str):
        # Si ya es un diccionario, devolverlo directamente
        if isinstance(text, dict):
            print("‚ö†Ô∏è La entrada ya es un diccionario, no requiere extracci√≥n.")
            return text
        else:
            print(f"‚ö†Ô∏è La entrada no es una cadena, es un {type(text)}. Intentando convertir...")
            text = str(text)
    
    # Guardar entrada original para depuraci√≥n
    try:
        os.makedirs("output", exist_ok=True)
        with open("output/extract_json_input.txt", "w", encoding="utf-8") as f:
            f.write(text)
    except Exception as e:
        print(f"‚ö†Ô∏è No se pudo guardar entrada para depuraci√≥n: {e}")
    
    # Buscar bloques de c√≥digo con json
    code_block = re.search(r"```(?:json)?\s*([\s\S]+?)\s*```", text)
    candidate = code_block.group(1) if code_block else text
    
    # Buscar el primer objeto JSON en el texto
    json_match = re.search(r"(\{[\s\S]*\})", candidate)
    json_str = json_match.group(1) if json_match else candidate
    
    # Limpieza b√°sica
    json_str = json_str.replace("\n", " ")
    json_str = re.sub(r"\s+", " ", json_str)
    json_str = re.sub(r"//.*", "", json_str)  # Eliminar comentarios
    json_str = re.sub(r",\s*([}\]])", r"\1", json_str)  # Eliminar comas colgantes
    
    # Reparar problemas comunes de sintaxis JSON
    # Insertar comas entre l√≠neas que parecen pares clave-valor
    lines = json_str.split("\n")
    fixed_json = ""
    for i, line in enumerate(lines):
        fixed_json += line
        if i < len(lines) - 1:
            current_line = line.strip()
            next_line = lines[i+1].strip()
            if ('"' in current_line and ':' in current_line and 
                not current_line.endswith(",") and 
                next_line.startswith('"')):
                fixed_json += ","
    
    json_str = fixed_json
    
    # Intentar cargar el JSON con diferentes estrategias
    last_exception = None
    try_count = 0
    
    # Estrategia 1: JSON original limpiado
    try:
        return json.loads(json_str)
    except Exception as e:
        last_exception = e
        try_count += 1
    
    # Estrategia 2: Eliminar espacios
    try:
        cleaned = re.sub(r"\s+", "", json_str)
        return json.loads(cleaned)
    except Exception as e:
        last_exception = e
        try_count += 1
    
    # Estrategia 3: Envolver en llaves si no est√°n
    try:
        if not json_str.startswith("{"):
            wrapped = "{" + json_str + "}"
            return json.loads(wrapped)
    except Exception as e:
        last_exception = e
        try_count += 1
    
    # Si todo falla, guardar para depuraci√≥n y lanzar error
    try:
        with open("output/llm_json_error.txt", "w", encoding="utf-8") as f:
            f.write(text)
        with open("output/llm_json_cleaned.txt", "w", encoding="utf-8") as f:
            f.write(json_str)
    except Exception:
        pass
    print(f"‚ùå Error al analizar JSON: {last_exception}")
    traceback.print_exc()
    # --- MEJORA ROBUSTA: nunca romper el flujo, devolver objeto vac√≠o profesional ---
    return {"error": "No se pudo extraer JSON", "detalle": str(last_exception)}

class CompetitorAnalysis:
    """
    An√°lisis competitivo LLM-first: el LLM genera el informe completo, y solo si lo pide se hace scraping puntual.
    """
    _init_logged = False
    SENER_CONTEXT = '''Sener: Ingenier√≠a, tecnolog√≠a e innovaci√≥n con visi√≥n global

Sener es un grupo privado de ingenier√≠a y tecnolog√≠a fundado en 1956, con sede en Espa√±a y una s√≥lida proyecci√≥n internacional. A lo largo de sus m√°s de seis d√©cadas de trayectoria, Sener se ha consolidado como un referente en la ejecuci√≥n de proyectos de alta complejidad t√©cnica, aportando soluciones innovadoras en sectores estrat√©gicos clave para el desarrollo sostenible y el progreso tecnol√≥gico.

√Åreas de especializaci√≥n:

Sener combina ingenier√≠a avanzada, desarrollo tecnol√≥gico y capacidad constructiva para ofrecer soluciones integrales que abarcan desde la consultor√≠a y dise√±o hasta la implementaci√≥n y operaci√≥n de sistemas complejos. Sus principales √°reas de enfoque incluyen:

Ingenier√≠a y construcci√≥n en sectores cr√≠ticos, aplicando altos est√°ndares de calidad, seguridad y sostenibilidad.

Desarrollo de sistemas y software a medida para sectores de alto valor estrat√©gico, como defensa, energ√≠a y transporte.

Innovaci√≥n tecnol√≥gica, con una fuerte inversi√≥n en I+D para el desarrollo de soluciones avanzadas que aporten valor diferencial a sus clientes.

Sectores clave de actividad:

Aeroespacial: Sener participa en misiones espaciales internacionales con el dise√±o, integraci√≥n y fabricaci√≥n de componentes y sistemas para sat√©lites, veh√≠culos espaciales y estaciones orbitales.

Infraestructuras y Transporte: Especialista en proyectos de gran escala como ferrocarriles, metros, carreteras y obras hidr√°ulicas, incluyendo dise√±o de trazados, estructuras, sistemas y gesti√≥n del transporte. Las l√≠neas estrat√©gicas que se estan abriendo y explorando en innovaci√≥n son hospital adaptable, transformaci√≥n de instalaciones deportivas y de entretenimiento en espacios multifuncionales, infraestructura para el veh√≠culo aut√≥nomo, puertos flotantes, centrales hidroel√©ctricas reversibles usando agua de mar, hiper-aprovechamiento de la infraestructura del metro.

Energ√≠a: Impulsa la transici√≥n energ√©tica mediante proyectos en energ√≠as renovables (solar, e√≥lica, hidr√≥geno verde), eficiencia energ√©tica, almacenamiento y soluciones inteligentes de red.

Digitalizaci√≥n: Lidera procesos de transformaci√≥n digital con soluciones de automatizaci√≥n, gemelos digitales, inteligencia artificial y sistemas ciberf√≠sicos aplicados a sectores industriales complejos.

Centros de datos: Infraestructura para los centros de datos

# -----------------------------------------------------------------------------
# COMPETIDORES BASE MONITORIZADOS (DEBEN VERIFICARSE PARA CADA IDEA)
# -----------------------------------------------------------------------------
# IMPORTANTE PARA EL LLM: La siguiente lista constituye una base de referencia
# de compa√±√≠as que hist√≥ricamente compiten con Sener.  NO significa que deban
# aparecer autom√°ticamente como competidores en todos los an√°lisis.  Para cada
# nueva idea o sector analizado, SOLO deben incluirse aquellos que presenten
# evidencia real (proyectos, patentes, soluciones, comunicaci√≥n oficial)
# alineada con la idea concreta.  Si la evidencia no existe o es d√©bil, el LLM
# deber√° omitirlos y buscar otros actores m√°s pertinentes.
#  ‚Ä¢  NUNCA incluyas a Sener como competidor.
#  ‚Ä¢  Justifica internamente (no en la respuesta) la inclusi√≥n de cada empresa.
#  ‚Ä¢  Prefiere siempre datos verificados sobre tama√±o, pa√≠s y foco tecnol√≥gico.
#
# 1) IDOM:  Movilidad sostenible; big-data/IA; soluciones energ√©ticas; optimizaci√≥n de procesos; innovaci√≥n y digitalizaci√≥n.
# 2) Abengoa:  Infraestructura ferroviaria; redes inteligentes 5E reversibles; proyectos de hidr√≥geno.
# 3) Typsa: Ingenier√≠a multidisciplinar; participaci√≥n ocasional en infraestructuras de transporte (baja relevancia tecnol√≥gica actual).
# 4) AECOM: Servicios globales de ingenier√≠a y consultor√≠a; proyectos de transporte y energ√≠a (revisar caso a caso).
# 5) Elecnor: Ingenier√≠a y construcci√≥n de grandes infraestructuras; presencia internacional (datos p√∫blicos limitados en √°reas deep-tech).
# 6) Atkins: Desarrollo de software y servicios de ingenier√≠a; experiencia en movilidad y planificaci√≥n.
# 7) ARUP: Dise√±o de infraestructuras; asset-management; mantenimiento; consultor√≠a digital avanzada.
# 8) Jacobs: Climate response; data solutions; consultor√≠a y advisory en grandes proyectos de infraestructura.
# 9) Indra: Automatizaci√≥n a√©rea; navegaci√≥n; drones; comunicaciones cr√≠ticas y sistemas de informaci√≥n.
# 10) Ineco: Cambio clim√°tico; renovables; optimizaci√≥n de procesos; innovaci√≥n y digitalizaci√≥n en transporte.
#
# El modelo debe evaluar cr√≠ticamente esta base y complementar O SUSTITUIR los
# nombres con otros competidores m√°s adecuados si el √°mbito tecnol√≥gico o de
# mercado de la IDEA lo requiere. MUY IMPORTANTE ANALIZARLO CRITICAMENTE
# -----------------------------------------------------------------------------
 '''
    def __init__(self, max_workers=4):
        print("üü¢ [CompetitorAnalysis] Inicializando clase CompetitorAnalysis...")
        self.max_workers = max_workers
        self.llm = None
        self.completion_llm = None
        self.output_dir = "output"
        os.makedirs(self.output_dir, exist_ok=True)
        self.public_downloads_dir = "public_downloads"
        os.makedirs(self.public_downloads_dir, exist_ok=True)
        self._initialize_llm()
    def _initialize_llm(self):
        print("üîÑ [CompetitorAnalysis] Inicializando modelo de lenguaje...")
        try:
            from openai_config import get_openai_client, get_deployment_name, AZURE_OPENAI_API_KEY, AZURE_OPENAI_ENDPOINT, API_VERSION
            self.openai_client = get_openai_client()
            self.deployment_name = get_deployment_name()
            try:
                import os
                os.environ["AZURE_OPENAI_API_KEY"] = AZURE_OPENAI_API_KEY
                os.environ["OPENAI_API_VERSION"] = API_VERSION
                os.environ["OPENAI_API_KEY"] = AZURE_OPENAI_API_KEY
                from langchain_openai import AzureChatOpenAI
                config = {
                    "deployment_name": self.deployment_name,
                    "model_name": self.deployment_name,
                    "azure_endpoint": AZURE_OPENAI_ENDPOINT,
                    "api_version": API_VERSION,
                    "api_key": AZURE_OPENAI_API_KEY,
                    "temperature": 0.7,
                    "max_retries": 3
                }
                llm = AzureChatOpenAI(**config)
                if not CompetitorAnalysis._init_logged:
                    print(f"‚úÖ Modelo LangChain inicializado correctamente: {self.deployment_name}")
                    print("‚úÖ self.llm y self.completion_llm asignados al modelo Azure/OpenAI")
                    CompetitorAnalysis._init_logged = True
                self.llm = llm
                self.completion_llm = llm
                return llm
            except Exception as langchain_error:
                if not CompetitorAnalysis._init_logged:
                    print(f"‚ö†Ô∏è No se pudo inicializar LangChain: {str(langchain_error)}")
                traceback.print_exc()
                print("‚ÑπÔ∏è Se utilizar√° llamada directa a la API")
                self.llm = None
                self.completion_llm = None
                return None
        except Exception as e:
            if not CompetitorAnalysis._init_logged:
                print(f"‚ùå Error al inicializar LLM: {str(e)}")
            traceback.print_exc()
            self.llm = None
            self.completion_llm = None
            return None
    
    # --- NUEVO: cach√© muy peque√±a para no llamar al LLM dos veces con la misma idea
    _sector_cache: dict = {}

    def _sector_terms(self, idea_text: str, k: int = 10) -> list[str]:
        """
        Devuelve la lista de keywords sectoriales usando un mini-LLM.
        - k = n¬∫ m√°ximo de keywords que quieres.
        - Si el LLM falla, usa fallback heur√≠stico.
        """
        import hashlib
        key = hashlib.sha1(idea_text.encode()).hexdigest()
        # 1. ¬øya lo tenemos cacheado?
        if key in self._sector_cache:
            return self._sector_cache[key]

        try:
            prompt = (
                "Eres analista competitivo. Devuelve SOLO un objeto JSON con esta forma:\n"
                '{ "sector": "<nombre-sector>", "keywords": ["kw1","kw2",...]} \n'
                "- sector debe ser 1-3 palabras y en min√∫sculas.\n"
                f"- keywords: entre 4 y {k} palabras/frases t√≠picas para buscar competidores.\n"
                "- No pongas texto fuera del JSON.\n\n"
                "IDEA:\n" + idea_text[:600]
            )

            resp = self.openai_client.chat.completions.create(
                model=self.deployment_name,
                messages=[
                    {"role": "system",
                     "content": "Eres un analista experto en detectar sectores y palabras clave."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=120,
                response_format={"type": "json_object"}
            )
            import json
            data = json.loads(resp.choices[0].message.content)
            kws  = [kw.strip() for kw in data.get("keywords", []) if kw.strip()]
            # m√≠nimo 3 keywords: si no, forzamos fallback
            if len(kws) >= 3:
                self._sector_cache[key] = kws[:k]
                # LRU manual: si supera 128 entradas, elimina la m√°s antigua
                if len(self._sector_cache) > 128:
                    oldest = next(iter(self._sector_cache))
                    del self._sector_cache[oldest]
                return kws[:k]

        except Exception as e:
            print(f"‚ö†Ô∏è _sector_terms LLM fall√≥: {e}")

        # --- Fallback: heur√≠stica ligera que ya ten√≠as
        basic = _extract_keywords(idea_text, k=3).split()
        fallback = basic + ["technology","market","solution"]
        return fallback[:k]

    @functools.lru_cache(maxsize=128)
    def llm_short_queries(self, idea: str, k: int = 6) -> list[str]:
        """
        Devuelve ‚â§k queries cort√≠simas (‚â§5 palabras, ‚â§40 chars),
        en ‚â•3 idiomas distintos, e incluye al menos 1 con 'filetype:pdf'.
        """
        # --- NUEVO: Usa function-calling y JsonOutputParser para queries robustas ---
        schema = JsonOutputParser()
        prompt = ChatPromptTemplate.from_messages([
            ("system",
             "Eres analista competitivo. Devuelve SOLO una lista JSON "
             f"con m√°x {k} strings (2-5 palabras, ‚â§40 car.). Usa ‚â•3 idiomas "
             "y al menos la mitad incluyen 'filetype:pdf'. Nada fuera del JSON."),
            ("user", idea[:400])
        ])
        try:
            chain = prompt | self.llm | schema
            result = chain.invoke({})
            uniq = list(dict.fromkeys(s.strip() for s in result if s.strip()))
            with_pdf = [q for q in uniq if "filetype:pdf" in q.lower()]
            if not with_pdf:
                kw = _extract_keywords(idea, k=1) or "market"
                uniq.append(f"{kw} filetype:pdf")
            return uniq[:k]
        except Exception as e:
            print(f"‚ö†Ô∏è generate_search_queries fallback: {e}")
            # --- Heur√≠stica propia si falla el LLM ---
            kw = _extract_keywords(idea, k=3)
            queries = []
            if kw:
                queries.append(kw)
                queries.append(f"{kw} filetype:pdf")
            try:
                from deep_translator import GoogleTranslator
                kw_en = GoogleTranslator(source='auto', target='en').translate(kw)
                queries.append(kw_en)
                queries.append(f"{kw_en} filetype:pdf")
                kw_fr = GoogleTranslator(source='auto', target='fr').translate(kw)
                queries.append(kw_fr)
                queries.append(f"{kw_fr} filetype:pdf")
            except Exception:
                pass
            if not queries:
                queries = ["market filetype:pdf", "competitors", "benchmarking filetype:pdf"]
            uniq = list(dict.fromkeys(q for q in queries if q and isinstance(q, str)))
            return uniq[:k]

    def generate_search_queries(self, idea_text: str, k: int = 6) -> list[str]:
        """
        Genera queries cortas y multi-idioma para b√∫squeda competitiva. Usa LLM y heur√≠stica como fallback.
        """
        from langchain_core.prompts import ChatPromptTemplate
        from langchain_core.output_parsers import JsonOutputParser
        schema = JsonOutputParser()
        prompt = ChatPromptTemplate.from_messages([
            ("system",
             "Eres analista competitivo. Devuelve SOLO una lista JSON "
             f"con m√°x {k} strings (2-5 palabras, ‚â§40 car.). Usa ‚â•3 idiomas "
             "y al menos la mitad incluyen 'filetype:pdf'. Nada fuera del JSON."),
            ("user", idea_text[:400])
        ])
        try:
            chain = prompt | self.llm | schema
            result = chain.invoke({})
            uniq = list(dict.fromkeys(s.strip() for s in result if s.strip()))
            with_pdf = [q for q in uniq if "filetype:pdf" in q.lower()]
            if not with_pdf:
                kw = _extract_keywords(idea_text, k=1) or "market"
                uniq.append(f"{kw} filetype:pdf")
            return uniq[:k]
        except Exception as e:
            print("‚ö†Ô∏è LLM queries fall√≥, usando heur√≠stica.")
            # --- Heur√≠stica propia si falla el LLM ---
            kw = _extract_keywords(idea_text, k=3)
            queries = []
            if kw:
                queries.append(kw)
                queries.append(f"{kw} filetype:pdf")
            try:
                from deep_translator import GoogleTranslator
                kw_en = GoogleTranslator(source='auto', target='en').translate(kw)
                queries.append(kw_en)
                queries.append(f"{kw_en} filetype:pdf")
                kw_fr = GoogleTranslator(source='auto', target='fr').translate(kw)
                queries.append(kw_fr)
                queries.append(f"{kw_fr} filetype:pdf")
            except Exception:
                pass
            if not queries:
                queries = ["market filetype:pdf", "competitors", "benchmarking filetype:pdf"]
            uniq = list(dict.fromkeys(q for q in queries if q and isinstance(q, str)))
            return uniq[:k]

    def _extract_competitors_from_mapping(self, report_dict):
        """
        Extrae todos los competidores identificados en COMPETITOR_MAPPING
        para usar en BENCHMARK_MATRIX (evitar duplicaci√≥n y asegurar consistencia)
        """
        competitors_list = []
        
        print(f"üîç [BENCHMARK-EXTRACT] Iniciando extracci√≥n de competidores...")
        print(f"üîç [BENCHMARK-EXTRACT] report_dict keys disponibles: {list(report_dict.keys()) if report_dict else 'None'}")
        
        if 'COMPETITOR_MAPPING' in report_dict and isinstance(report_dict['COMPETITOR_MAPPING'], dict):
            # üö® CRITICAL FIX: Handle both direct data and wrapped data structure
            raw_mapping = report_dict['COMPETITOR_MAPPING']
            if 'datos' in raw_mapping and isinstance(raw_mapping['datos'], dict):
                mapping_data = raw_mapping['datos']  # Unwrap from {'datos': ..., 'texto': ...} structure
                print(f"üîç [BENCHMARK-EXTRACT] Using wrapped data structure")
            else:
                mapping_data = raw_mapping  # Direct data structure
                print(f"üîç [BENCHMARK-EXTRACT] Using direct data structure")
            print(f"üîç [BENCHMARK-EXTRACT] COMPETITOR_MAPPING keys: {list(mapping_data.keys())}")
            
            # Extraer de las 3 categor√≠as tradicionales
            categories = ['competidores_directos', 'competidores_indirectos', 'emergentes']
            for category in categories:
                if category in mapping_data and isinstance(mapping_data[category], list):
                    print(f"üîç [BENCHMARK-EXTRACT] Procesando categor√≠a '{category}' con {len(mapping_data[category])} items")
                    for i, comp in enumerate(mapping_data[category]):
                        if isinstance(comp, dict) and comp.get('nombre'):
                            competitors_list.append({
                                'nombre': comp['nombre'],
                                'categoria': category,
                                'sector': comp.get('sector', ''),
                                'tamano': comp.get('tamano', ''),
                                'pais': comp.get('pais', ''),
                                'descripcion': comp.get('descripcion', '')
                            })
                            print(f"  ‚úÖ Extra√≠do: {comp['nombre']} ({category})")
                        else:
                            print(f"  ‚ö†Ô∏è Item {i} en {category} no v√°lido: {comp}")
                else:
                    print(f"üîç [BENCHMARK-EXTRACT] Categor√≠a '{category}' no encontrada o no es lista")
            
            # üîß NUEVA B√öSQUEDA: Tambi√©n buscar en estructuras alternativas
            alternative_keys = ['empresas_competidoras', 'competidores_principales', 'main_competitors', 'competidores']
            for alt_key in alternative_keys:
                if alt_key in mapping_data and isinstance(mapping_data[alt_key], list):
                    print(f"üîç [BENCHMARK-EXTRACT] Encontrada estructura alternativa '{alt_key}' con {len(mapping_data[alt_key])} items")
                    for comp in mapping_data[alt_key]:
                        if isinstance(comp, dict) and comp.get('nombre'):
                            # Evitar duplicados
                            if not any(existing['nombre'] == comp['nombre'] for existing in competitors_list):
                                competitors_list.append({
                                    'nombre': comp['nombre'],
                                    'categoria': 'extraido_alternativo',
                                    'sector': comp.get('sector', ''),
                                    'tamano': comp.get('tamano', ''),
                                    'pais': comp.get('pais', ''),
                                    'descripcion': comp.get('descripcion', '')
                                })
                                print(f"  ‚úÖ Extra√≠do (alternativo): {comp['nombre']}")
                        elif isinstance(comp, str):
                            # Casos donde el competidor es solo un string
                            if not any(existing['nombre'] == comp for existing in competitors_list):
                                competitors_list.append({
                                    'nombre': comp,
                                    'categoria': 'extraido_alternativo',
                                    'sector': '',
                                    'tamano': '',
                                    'pais': '',
                                    'descripcion': ''
                                })
                                print(f"  ‚úÖ Extra√≠do (string): {comp}")
        else:
            print(f"‚ö†Ô∏è [BENCHMARK-EXTRACT] No se encontr√≥ COMPETITOR_MAPPING v√°lido")
        
        print(f"‚úÖ [BENCHMARK-EXTRACT] TOTAL extra√≠dos: {len(competitors_list)} competidores de COMPETITOR_MAPPING")
        for i, comp in enumerate(competitors_list):
            print(f"  {i+1}. {comp['nombre']} ({comp['categoria']})")
        
        return competitors_list

    def _generate_benchmark_prompt_with_competitors(self, competitors_list, shared_inputs):
        """
        Genera prompt espec√≠fico de BENCHMARK_MATRIX incluyendo los competidores ya identificados
        para asegurar consistencia y evitar duplicaci√≥n
        """
        if not competitors_list:
            print("‚ö†Ô∏è [BENCHMARK] No hay competidores disponibles, usando prompt gen√©rico")
            # Retornar prompt gen√©rico b√°sico
            return """
            Genera tabla comparativa CUANTITATIVA para BENCHMARK_MATRIX.
            ESTRUCTURA JSON REQUERIDA: 'tabla_comparativa', 'metricas_comparativas', 'gaps_cuantitativos'
            USA SOLO m√©tricas num√©ricas espec√≠ficas. NO texto descriptivo largo.
            """
        
        # Crear lista detallada de competidores para el prompt
        competitors_text = "\n".join([
            f"- {comp['nombre']} (Categor√≠a: {comp['categoria']}, Tama√±o: {comp['tamano']}, Sector: {comp['sector']}, Pa√≠s: {comp['pais']})"
            for comp in competitors_list
        ])
        
        # Usar las instrucciones b√°sicas de BENCHMARK_MATRIX con FORZADO ABSOLUTO
        competitors_names = [comp.get('nombre', '') for comp in competitors_list if comp.get('nombre')]
        competitors_names_simple = ", ".join(competitors_names[:8])  # L√≠mite de 8 para no saturar
        
        base_prompt = f"""
        Instrucciones para la tabla comparativa:

        ‚Ä¢ Utiliza √∫nicamente las siguientes empresas como filas de la tabla: {competitors_names_simple}
        ‚Ä¢ No incluyas empresas gen√©ricas (por ejemplo Siemens, GE, ABB, Schneider, etc.) salvo que aparezcan en la lista anterior.
        ‚Ä¢ Elabora m√©tricas cuantitativas realistas para cada compa√±√≠a; si no dispones de un dato fiable, escribe "N/D".
        ‚Ä¢ Devuelve siempre un objeto JSON con tres claves: 'tabla_comparativa', 'metricas_comparativas', 'gaps_cuantitativos'.
        ‚Ä¢ No introduzcas ning√∫n otro texto fuera del JSON.

        Recuerda que Sener no debe figurar como competidor.
        """
        
        # Prompt espec√≠fico con los competidores extra√≠dos
        enhanced_prompt = f"""
COMPETIDORES ESPEC√çFICOS A ANALIZAR (usar EXACTAMENTE estos {len(competitors_list)} competidores):

{competitors_text}

IDEA ANALIZADA: {shared_inputs.get('idea_brief', shared_inputs.get('idea_text', ''))[:300]}...
SECTOR ESPEC√çFICO: {shared_inputs.get('brief', '')}
CONTEXTO: {shared_inputs.get('contexto_usuario', shared_inputs.get('context', ''))[:200]}...

INSTRUCCIONES ESPEC√çFICAS PARA ESTA IDEA:

{base_prompt}

üö®üö®üö® FORMATO JSON OBLIGATORIO - NO USAR 'tabla' üö®üö®üö®
CR√çTICO: Tu respuesta JSON debe incluir TODOS los competidores listados arriba en 'tabla_comparativa'.
üö´ PROHIBIDO: NO usar campo 'tabla' - SOLO 'tabla_comparativa' 
‚úÖ OBLIGATORIO: Usar exactamente 'tabla_comparativa', 'metricas_comparativas', 'gaps_cuantitativos'
Para cada empresa, estima las m√©tricas bas√°ndote en:
1. Su categor√≠a (directos/indirectos/emergentes)  
2. Su tama√±o declarado (Peque√±a/Mediana/Grande/Multinacional)
3. Su sector espec√≠fico
4. El contexto de la idea analizada

EJEMPLO DE ESTRUCTURA DE RESPUESTA:
{{
  "tabla_comparativa": [
    {{"nombre": "Primer competidor de la lista", "ingresos_anuales_millones_eur": [cifra estimada], "empleados_total": [cifra estimada], ...}},
    {{"nombre": "Segundo competidor de la lista", "ingresos_anuales_millones_eur": [cifra estimada], "empleados_total": [cifra estimada], ...}},
    ... (continuar con TODOS los competidores listados)
  ],
  "metricas_comparativas": {{
    "lider_ingresos": {{"empresa": "[nombre del l√≠der]", "valor": [cifra]}},
    ...
  }},
  "gaps_cuantitativos": [...]
}}

üî• VERIFICACI√ìN FINAL: Tu JSON DEBE contener 'tabla_comparativa' (NO 'tabla') üî•
"""
        
        print(f"‚úÖ [BENCHMARK] Prompt generado con {len(competitors_list)} competidores espec√≠ficos")
        return enhanced_prompt

    def _validate_benchmark_competitor_coherence(self, benchmark_data, report_dict):
        """
        üéØ NUEVA FUNCI√ìN ROBUSTA: Valida que las empresas del benchmark sean coherentes con COMPETITOR_MAPPING
        Si hay inconsistencias cr√≠ticas, regenera usando competidores espec√≠ficos.
        """
        try:
            if not report_dict or not isinstance(benchmark_data, dict):
                print("‚ö†Ô∏è [BENCHMARK-COHERENCE] No hay datos suficientes para validaci√≥n de coherencia")
                return benchmark_data
            
            # 1. Extraer competidores del COMPETITOR_MAPPING si existe
            mapping_competitors = []
            if 'COMPETITOR_MAPPING' in report_dict:
                mapping_data = report_dict['COMPETITOR_MAPPING']
                if isinstance(mapping_data, dict):
                    # Extraer de diferentes campos posibles
                    for key in ['empresas_competidoras', 'competidores_principales', 'main_competitors']:
                        if key in mapping_data and isinstance(mapping_data[key], list):
                            for comp in mapping_data[key]:
                                if isinstance(comp, dict) and 'nombre' in comp:
                                    mapping_competitors.append(comp['nombre'].strip())
                                elif isinstance(comp, str):
                                    mapping_competitors.append(comp.strip())
                    
                    # Tambi√©n buscar en estructura plana
                    if 'competidores' in mapping_data and isinstance(mapping_data['competidores'], list):
                        for comp in mapping_data['competidores']:
                            if isinstance(comp, str):
                                mapping_competitors.append(comp.strip())
            
            # Limpiar competidores extra√≠dos
            mapping_competitors = [comp for comp in mapping_competitors if comp and len(comp) > 2]
            # ---- NUEVO: si la lista sigue vac√≠a, extraer de las claves est√°ndar ----
            if not mapping_competitors and 'COMPETITOR_MAPPING' in report_dict:
                try:
                    full_list = self._extract_competitors_from_mapping(report_dict)
                    mapping_competitors = [c['nombre'] for c in full_list if c.get('nombre')]
                except Exception:
                    pass
            # -----------------------------------------------------------------------
            
            if not mapping_competitors:
                print("‚ÑπÔ∏è [BENCHMARK-COHERENCE] No se encontraron competidores espec√≠ficos en COMPETITOR_MAPPING")
                return benchmark_data
            
            print(f"üìã [BENCHMARK-COHERENCE] Competidores del mapping: {mapping_competitors}")
            
            # 2. Extraer competidores del benchmark actual
            benchmark_competitors = []
            tabla_key = 'tabla_comparativa' if 'tabla_comparativa' in benchmark_data else 'tabla'
            
            if tabla_key in benchmark_data and isinstance(benchmark_data[tabla_key], list):
                for comp in benchmark_data[tabla_key]:
                    if isinstance(comp, dict) and 'nombre' in comp:
                        nombre = comp['nombre'].strip()
                        if 'sener' not in nombre.lower():
                            benchmark_competitors.append(nombre)
            
            print(f"üìä [BENCHMARK-COHERENCE] Competidores en benchmark: {benchmark_competitors}")
            
            # 3. Calcular coincidencias usando comparaci√≥n fuzzy
            import difflib
            
            coincidencias = 0
            mapping_lower = [comp.lower() for comp in mapping_competitors]
            
            for bench_comp in benchmark_competitors:
                bench_lower = bench_comp.lower()
                
                # Buscar coincidencias exactas
                if bench_lower in mapping_lower:
                    coincidencias += 1
                    continue
                
                # Buscar coincidencias fuzzy (>= 0.8 de similitud)
                for map_comp_lower in mapping_lower:
                    similarity = difflib.SequenceMatcher(None, bench_lower, map_comp_lower).ratio()
                    if similarity >= 0.8:
                        coincidencias += 1
                        break
            
            coherence_ratio = coincidencias / len(benchmark_competitors) if benchmark_competitors else 0
            print(f"üìà [BENCHMARK-COHERENCE] Ratio de coherencia: {coherence_ratio:.2f} ({coincidencias}/{len(benchmark_competitors)})")
            
            # 4. Si la coherencia es baja (< 50%), intentar correcci√≥n autom√°tica
            if coherence_ratio < 0.5 and len(mapping_competitors) >= 3:
                print(f"üîß [BENCHMARK-COHERENCE] Coherencia baja ({coherence_ratio:.2f}), aplicando correcci√≥n autom√°tica...")
                
                # Mantener estructura pero reemplazar empresas
                if tabla_key in benchmark_data and isinstance(benchmark_data[tabla_key], list):
                    tabla_original = benchmark_data[tabla_key]
                    
                    # Tomar hasta los primeros N competidores del mapping
                    max_competitors = min(len(tabla_original), len(mapping_competitors), 5)
                    
                    for i in range(max_competitors):
                        if i < len(tabla_original) and isinstance(tabla_original[i], dict):
                            # Reemplazar nombre pero mantener estructura de m√©tricas
                            tabla_original[i]['nombre'] = mapping_competitors[i]
                            print(f"‚úÖ [BENCHMARK-COHERENCE] Competidor {i+1} corregido: {mapping_competitors[i]}")
                    
                    # Si hay menos competidores en el mapping, truncar la tabla
                    if len(mapping_competitors) < len(tabla_original):
                        benchmark_data[tabla_key] = tabla_original[:len(mapping_competitors)]
                        print(f"üìä [BENCHMARK-COHERENCE] Tabla truncada a {len(mapping_competitors)} competidores")
                
                print(f"‚úÖ [BENCHMARK-COHERENCE] Correcci√≥n autom√°tica aplicada usando competidores del mapping")
            
            elif coherence_ratio >= 0.5:
                print(f"‚úÖ [BENCHMARK-COHERENCE] Coherencia aceptable ({coherence_ratio:.2f}), manteniendo benchmark actual")
            
            else:
                print(f"‚ÑπÔ∏è [BENCHMARK-COHERENCE] Coherencia baja pero pocos competidores en mapping, manteniendo benchmark")
            
            return benchmark_data
            
        except Exception as e:
            print(f"‚ö†Ô∏è [BENCHMARK-COHERENCE] Error en validaci√≥n de coherencia: {str(e)}")
            return benchmark_data

    def _validate_benchmark_metrics(self, benchmark_data):
        """
        Valida y normaliza datos cuantitativos de benchmarking
        Convierte strings a n√∫meros y asegura consistencia de datos
        """
        if not isinstance(benchmark_data, dict):
            return benchmark_data
        
        # Campos num√©ricos requeridos
        numeric_fields = [
            'ingresos_anuales_millones_eur',
            'empleados_total', 
            'a√±os_en_mercado',
            'paises_presencia',
            'proyectos_anuales_estimados',
            'precio_promedio_proyecto_millones',
            'cuota_mercado_sector_porcentaje',
            'gasto_id_porcentaje_ingresos',
            'certificaciones_principales',
            'patentes_activas_estimadas'
        ]
        
        # üîß NOTA: La conversi√≥n 'tabla' ‚Üí 'tabla_comparativa' ya se hizo antes de llamar esta funci√≥n
        
        # üö® DETECTAR Y RECHAZAR DATOS PLACEHOLDER GEN√âRICOS
        if 'tabla_comparativa' in benchmark_data and isinstance(benchmark_data['tabla_comparativa'], list):
            placeholders_detectados = []
            for i, comp in enumerate(benchmark_data['tabla_comparativa']):
                if isinstance(comp, dict):
                    nombre = comp.get('nombre', '').lower()
                    enfoque = comp.get('enfoque_estrategico', '').lower()
                    
                    # Detectar texto placeholder/gen√©rico
                    placeholders = [
                        'an√°lisis comparativo en desarrollo',
                        'requiere estudio espec√≠fico',
                        'evaluaci√≥n de modelos en proceso',
                        'an√°lisis en desarrollo',
                        'pendiente de an√°lisis',
                        'informaci√≥n en desarrollo',
                        'requiere investigaci√≥n',
                        'datos en proceso',
                        'por determinar'
                    ]
                    
                    es_placeholder = any(placeholder in nombre or placeholder in enfoque for placeholder in placeholders)
                    
                    if es_placeholder:
                        placeholders_detectados.append(f"'{nombre}' (√≠ndice {i})")
            
            if placeholders_detectados:
                print(f"üö® [BENCHMARK] DATOS PLACEHOLDER DETECTADOS: {', '.join(placeholders_detectados)}")
                print(f"üö® [BENCHMARK] ¬°EL LLM EST√Å GENERANDO DATOS GEN√âRICOS EN LUGAR DE EMPRESAS REALES!")
                # Limpiar datos placeholder
                benchmark_data['tabla_comparativa'] = [
                    comp for comp in benchmark_data['tabla_comparativa']
                    if not any(placeholder in comp.get('nombre', '').lower() or 
                             placeholder in comp.get('enfoque_estrategico', '').lower() 
                             for placeholder in placeholders)
                ]
                print(f"üßπ [BENCHMARK] Competidores v√°lidos restantes: {len(benchmark_data['tabla_comparativa'])}")
                
                # Si no quedan competidores v√°lidos, marcar como fallo
                if not benchmark_data['tabla_comparativa']:
                    print("‚ùå [BENCHMARK] NO HAY COMPETIDORES V√ÅLIDOS - LLM fall√≥ completamente")
                    return None
        
        # Validar tabla_comparativa
        if 'tabla_comparativa' in benchmark_data and isinstance(benchmark_data['tabla_comparativa'], list):
            for i, comp in enumerate(benchmark_data['tabla_comparativa']):
                if isinstance(comp, dict):
                    # Asegurar que existe el nombre
                    if not comp.get('nombre'):
                        comp['nombre'] = f"Competidor {i+1}"
                    
                    # Convertir campos num√©ricos
                    for field in numeric_fields:
                        if field in comp:
                            try:
                                # Manejar expl√≠citamente N/D y valores faltantes
                                value = comp[field]
                                if isinstance(value, str):
                                    value_clean = value.strip()
                                    # Permitir N/D expl√≠citamente
                                    if value_clean.upper() in ['N/D', 'N/A', 'DESCONOCIDO', 'NO DISPONIBLE']:
                                        comp[field] = 'N/D'
                                    else:
                                        # Intentar extraer n√∫mero del texto
                                        import re
                                        numbers = re.findall(r'[\d.]+', value.replace(',', ''))
                                        if numbers:
                                            comp[field] = float(numbers[0])
                                        else:
                                            comp[field] = 'N/D'
                                else:
                                    comp[field] = float(value) if value else 'N/D'
                            except (ValueError, TypeError):
                                comp[field] = 'N/D'
                        else:
                            comp[field] = 'N/D'
        
        # Validar m√©tricas comparativas
        if 'metricas_comparativas' in benchmark_data:
            metrics = benchmark_data['metricas_comparativas']
            for metric_key in ['lider_ingresos', 'lider_empleados', 'lider_cuota_mercado']:
                if metric_key in metrics and isinstance(metrics[metric_key], dict):
                    if 'valor' in metrics[metric_key]:
                        try:
                            value = metrics[metric_key]['valor']
                            if isinstance(value, str) and value.strip().upper() in ['N/D', 'N/A', 'DESCONOCIDO', 'NO DISPONIBLE']:
                                metrics[metric_key]['valor'] = 'N/D'
                            else:
                                metrics[metric_key]['valor'] = float(value)
                        except:
                            metrics[metric_key]['valor'] = 'N/D'
            
            # Promedios del sector
            for avg_key in ['promedio_sector_ingresos', 'promedio_sector_empleados']:
                if avg_key in metrics:
                    try:
                        value = metrics[avg_key]
                        if isinstance(value, str) and value.strip().upper() in ['N/D', 'N/A', 'DESCONOCIDO', 'NO DISPONIBLE']:
                            metrics[avg_key] = 'N/D'
                        else:
                            metrics[avg_key] = float(value)
                    except:
                        metrics[avg_key] = 'N/D'
        
        print(f"‚úÖ [BENCHMARK] Datos m√©tricos validados y normalizados")
        return benchmark_data

    def _validate_and_filter_competitors(self, data):
        """
        Valida y filtra autom√°ticamente los datos de competidores para excluir a Sener
        y mejorar la calidad de los competidores identificados.
        """
        def should_exclude_competitor(company_name):
            """Determina si un competidor debe ser excluido"""
            if not company_name or not isinstance(company_name, str):
                return True
            
            name_lower = company_name.lower().strip()
            
            # Excluir Sener autom√°ticamente
            if 'sener' in name_lower:
                return True
            
            # Excluir nombres muy gen√©ricos o sospechosos
            generic_names = [
                'ejemplo', 'company', 'corporation', 'inc', 'ltd', 'limited',
                'business', 'enterprise', 'group', 'holdings', 'unknown'
            ]
            
            if any(generic in name_lower for generic in generic_names):
                return True
                
            # Excluir nombres muy cortos (probablemente incompletos)
            if len(name_lower) < 3:
                return True
                
            return False
        
        def clean_competitor_list(competitors_list):
            """Limpia una lista de competidores"""
            if not isinstance(competitors_list, list):
                return []
            
            cleaned = []
            for comp in competitors_list:
                if isinstance(comp, dict):
                    name_fields = ['nombre', 'empresa', 'name', 'company']
                    company_name = None
                    
                    for field in name_fields:
                        if field in comp and comp[field]:
                            company_name = comp[field]
                            break
                    
                    if not should_exclude_competitor(company_name):
                        cleaned.append(comp)
                        
                elif isinstance(comp, str):
                    if not should_exclude_competitor(comp):
                        cleaned.append(comp)
            
            return cleaned
        
        if isinstance(data, dict):
            # Filtrar competidores directos
            if 'competidores_directos' in data:
                data['competidores_directos'] = clean_competitor_list(data['competidores_directos'])
            
            # Filtrar competidores indirectos
            if 'competidores_indirectos' in data:
                data['competidores_indirectos'] = clean_competitor_list(data['competidores_indirectos'])
            
            # Filtrar emergentes
            if 'emergentes' in data:
                data['emergentes'] = clean_competitor_list(data['emergentes'])
        
        return data

    def _extract_section_data_llm(self, section_id, shared_inputs, report_dict=None):
        """
        Llama al LLM para extraer SOLO datos objetivos y estructurados para la secci√≥n, con m√°xima exigencia consultiva.
        ‚úÖ MEJORADO: B√∫squeda real de patentes para TECH_IP_LANDSCAPE
        ‚úÖ NUEVO: L√≥gica especial para BENCHMARK_MATRIX usando competidores de COMPETITOR_MAPPING
        """
        import json
        
        # ‚úÖ INICIALIZAR: prompt espec√≠fico para BENCHMARK_MATRIX
        specific_benchmark_prompt = None
        
        # ‚úÖ NUEVA L√ìGICA: Manejar BENCHMARK_MATRIX de forma especial
        print(f"üö®üö®üö® [DEBUG-SECTION] section_id recibido: '{section_id}' (tipo: {type(section_id)})")
        print(f"üö®üö®üö® [DEBUG-SECTION] ¬øEs BENCHMARK_MATRIX?: {section_id == 'BENCHMARK_MATRIX'}")
        print(f"üö®üö®üö® [DEBUG-SECTION] ¬øContiene BENCHMARK?: {'BENCHMARK' in str(section_id)}")
        
        if section_id == "BENCHMARK_MATRIX":
            print(f"üö®üö®üö® [BENCHMARK-EXTRACT] === INICIANDO BENCHMARK_MATRIX ESPECIAL ===")
            print(f"üö®üö®üö® [BENCHMARK-EXTRACT] report_dict keys: {list(report_dict.keys()) if report_dict else 'None'}")
            print(f"üö®üö®üö® [BENCHMARK-EXTRACT] report_dict es None?: {report_dict is None}")
            print(f"üö®üö®üö® [BENCHMARK-EXTRACT] Tipo de report_dict: {type(report_dict)}")
            
            if report_dict and 'COMPETITOR_MAPPING' in report_dict:
                print(f"üö®üö®üö® [BENCHMARK-EXTRACT] COMPETITOR_MAPPING encontrado! Tipo: {type(report_dict['COMPETITOR_MAPPING'])}")
                print(f"üö®üö®üö® [BENCHMARK-EXTRACT] Contenido COMPETITOR_MAPPING: {str(report_dict['COMPETITOR_MAPPING'])[:300]}...")
            else:
                print(f"üö®üö®üö® [BENCHMARK-EXTRACT] COMPETITOR_MAPPING NO ENCONTRADO!")
                if report_dict:
                    print(f"üö®üö®üö® [BENCHMARK-EXTRACT] Keys disponibles: {list(report_dict.keys())}")
            
            competitors_list = self._extract_competitors_from_mapping(report_dict or {})
            print(f"üö®üö®üö® [BENCHMARK-EXTRACT] Competitors extra√≠dos: {len(competitors_list)}")
            
            if competitors_list:
                print(f"üîÑ [BENCHMARK] Generando an√°lisis cuantitativo para {len(competitors_list)} competidores espec√≠ficos")
                for i, comp in enumerate(competitors_list):
                    print(f"üö®üö®üö® [BENCHMARK-EXTRACT] Competidor {i+1}: {comp.get('nombre', 'SIN_NOMBRE')}")
                
                specific_benchmark_prompt = self._generate_benchmark_prompt_with_competitors(competitors_list, shared_inputs)
                print(f"üö®üö®üö® [BENCHMARK-EXTRACT] Prompt espec√≠fico generado: {len(specific_benchmark_prompt)} caracteres")
                print(f"üö®üö®üö® [BENCHMARK-EXTRACT] === PROMPT FINAL PARA LLM ===")
                print(f"üö®üö®üö® [BENCHMARK-EXTRACT] Primeros 200 chars: {specific_benchmark_prompt[:200]}...")
                
                # Verificar si contiene competidores espec√≠ficos
                competitor_names = [comp.get('nombre', '') for comp in competitors_list if comp.get('nombre')]
                found_competitors = [name for name in competitor_names if name in specific_benchmark_prompt]
                
                if found_competitors or 'Blue Ocean' in specific_benchmark_prompt:
                    print(f"‚úÖ‚úÖ‚úÖ [BENCHMARK-EXTRACT] PROMPT CONTIENE COMPETIDORES: {found_competitors}")
                else:
                    print(f"‚ùå‚ùå‚ùå [BENCHMARK-EXTRACT] PROMPT NO CONTIENE COMPETIDORES DE: {competitor_names}")
                    print(f"‚ùå‚ùå‚ùå [BENCHMARK-EXTRACT] Contenido del prompt: {specific_benchmark_prompt[-500:]}")  # √öltimos 500 chars
            else:
                print(f"‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è [BENCHMARK-EXTRACT] No hay competidores disponibles, usando prompt gen√©rico")
        
        schema = SECTION_SCHEMAS.get(section_id, '{}')
        other_context = shared_inputs.get('contexto_usuario', '')
        if report_dict:
            context_parts = []
            for k, v in report_dict.items():
                if k != section_id and isinstance(v, dict):
                    context_parts.append(f"[{k}]: {json.dumps(v, ensure_ascii=False)[:400]}")
            if context_parts:
                other_context += "\n\n" + "\n".join(context_parts)
        
        # üö´ ELIMINADA: B√∫squeda externa de patentes (no funciona bien)
        # Nuevo enfoque: Solo an√°lisis basado en conocimiento espec√≠fico del LLM
        real_patents_context = ""
        
        extraction_instructions = {
            "EXEC_SUMMARY": "No extraigas datos, solo redacta al final.",
            "COMPETITOR_MAPPING": (
                "Identifica competidores REALES del sector espec√≠fico de la idea analizada. "
                "CR√çTICO: NO uses listas predefinidas de empresas - analiza el sector espec√≠fico de cada idea. "
                "Devuelve JSON con 3 categor√≠as: competidores_directos (mismo mercado y soluci√≥n), "
                "competidores_indirectos (mercado relacionado), emergentes (startups y nuevos entrantes). "
                
                "CAMPOS OBLIGATORIOS para cada competidor: "
                "- nombre: Nombre oficial de la empresa "
                "- pais: Pa√≠s donde tiene su sede principal "
                "- sector: Sector espec√≠fico (ej: 'Infraestructura', 'Energ√≠a renovable', 'Aeroespacial', 'Construcci√≥n', 'Tecnolog√≠a') "
                "- tamano: Tama√±o de la empresa ('Peque√±a', 'Mediana', 'Grande', 'Multinacional') "
                "- descripcion: Breve descripci√≥n de qu√© hace la empresa "
                "- website: URL si disponible "
                
                "FORMATO JSON POR COMPETIDOR: "
                "{\"nombre\":\"Empresa Real\", \"pais\":\"Pa√≠s\", \"sector\":\"Sector espec√≠fico\", "
                "\"tamano\":\"Tama√±o real\", \"descripcion\":\"Qu√© hace\", \"website\":\"URL\"} "
                
                "CRITERIOS DE TAMA√ëO (usar informaci√≥n real): "
                "- 'Peque√±a': <100 empleados, local/regional "
                "- 'Mediana': 100-1000 empleados, nacional "
                "- 'Grande': >1000 empleados, multinacional "
                "- 'Multinacional': >5000 empleados, presencia global "
                
                "M√ÅXIMO 3-4 empresas por categor√≠a. "
                "SOLO empresas REALES verificables - NO inventar nombres ni usar ejemplos gen√©ricos. "
                "PROHIBIDO: incluir Sener como competidor (es quien hace el an√°lisis). "
                "Enf√≥cate en empresas que realmente operan en el sector espec√≠fico de la idea analizada."
            ),
            "BENCHMARK_MATRIX": (
                "Genera tabla comparativa CUANTITATIVA usando los MISMOS competidores identificados en COMPETITOR_MAPPING. "
                "CR√çTICO: Reutiliza EXACTAMENTE las empresas listadas en las 3 categor√≠as de COMPETITOR_MAPPING (directos, indirectos, emergentes). "
                "NUNCA incluyas a Sener - Sener es quien hace el an√°lisis, NO un competidor. "
                "ENFOQUE: SOLO m√©tricas num√©ricas y cifras espec√≠ficas, NO texto descriptivo largo. "
                
                "ESTRUCTURA JSON REQUERIDA: "
                "- 'tabla_comparativa': lista de competidores con m√©tricas cuantitativas "
                "- 'metricas_comparativas': rankings y estad√≠sticas del sector "
                "- 'gaps_cuantitativos': brechas identificadas con datos num√©ricos "
                
                "CAMPOS OBLIGATORIOS por competidor en 'tabla_comparativa' (SOLO N√öMEROS): "
                "- nombre: Nombre de la empresa (EXACTAMENTE igual que en COMPETITOR_MAPPING) "
                "- ingresos_anuales_millones_eur: Facturaci√≥n anual en millones EUR (estimar bas√°ndose en tama√±o) "
                "- empleados_total: N√∫mero total de empleados (aproximaci√≥n realista) "
                "- a√±os_en_mercado: A√±os operando en el sector espec√≠fico "
                "- paises_presencia: N√∫mero de pa√≠ses donde tiene operaciones "
                "- proyectos_anuales_estimados: Grandes proyectos ejecutados por a√±o "
                "- precio_promedio_proyecto_millones: Valor promedio de proyectos en millones EUR "
                "- cuota_mercado_sector_porcentaje: Porcentaje estimado de cuota en el sector espec√≠fico "
                "- gasto_id_porcentaje_ingresos: Porcentaje de ingresos destinado a I+D+i "
                "- certificaciones_principales: N√∫mero de certificaciones ISO/t√©cnicas relevantes "
                "- patentes_activas_estimadas: N√∫mero aproximado de patentes activas en el sector "
                
                "GU√çAS DE ESTIMACI√ìN INTELIGENTE ( SOLO Y EXCLUSIVEMNETE si no conoces datos exactos): "
                
                "Para empresas categorizadas como 'Peque√±a': "
                "- ingresos_anuales_millones_eur: 10-80 (estimar seg√∫n sector) "
                "- empleados_total: 50-300 "
                "- a√±os_en_mercado: 5-20 "
                "- paises_presencia: 1-3 "
                "- cuota_mercado_sector_porcentaje: 0.5-3 "
                
                "Para empresas categorizadas como 'Mediana': "
                "- ingresos_anuales_millones_eur: 80-800 "
                "- empleados_total: 300-3000 "
                "- a√±os_en_mercado: 15-40 "
                "- paises_presencia: 3-15 "
                "- cuota_mercado_sector_porcentaje: 3-12 "
                
                "Para empresas categorizadas como 'Grande': "
                "- ingresos_anuales_millones_eur: 800-8000 "
                "- empleados_total: 3000-50000 "
                "- a√±os_en_mercado: 25-80 "
                "- paises_presencia: 10-50 "
                "- cuota_mercado_sector_porcentaje: 8-25 "
                
                "Para empresas categorizadas como 'Multinacional': "
                "- ingresos_anuales_millones_eur: 5000-150000 "
                "- empleados_total: 20000-400000 "
                "- a√±os_en_mercado: 30-150 "
                "- paises_presencia: 25-100 "
                "- cuota_mercado_sector_porcentaje: 15-40 "
                
                "ESTRUCTURA 'metricas_comparativas' OBLIGATORIA: "
                "- lider_ingresos: {empresa: nombre, valor: cifra} "
                "- lider_empleados: {empresa: nombre, valor: cifra} "
                "- lider_cuota_mercado: {empresa: nombre, valor: cifra} "
                "- promedio_sector_ingresos: cifra promedio "
                "- promedio_sector_empleados: cifra promedio "
                
                "ESTRUCTURA 'gaps_cuantitativos' (2-4 elementos): "
                "- metrica: Nombre espec√≠fico de la m√©trica (ej: 'Inversi√≥n I+D', 'Presencia internacional') "
                "- brecha_identificada: Descripci√≥n cuantitativa del gap (ej: 'Promedio sector 3.2%, l√≠der 8.1%') "
                "- oportunidad_sener: Ventaja num√©rica espec√≠fica para Sener (ej: 'Incrementar I+D al 5% puede captar 15% m√°s proyectos') "
                
                "PRINCIPIOS DE ESTIMACI√ìN INTELIGENTE: "
                "1. DATOS CONOCIDOS: Si tienes conocimiento real de una empresa, √∫salo "
                "2. ESTIMACI√ìN CONTEXTUAL: Para empresas que no conoces, estima bas√°ndote en el tama√±o/sector "
                "3. HONESTIDAD: Si no tienes datos confiables, usar 'N/D' es OBLIGATORIO "
                
                "CATEGOR√çAS DE ESTIMACI√ìN POR TAMA√ëO: "
                "- Multinacional Grande (Siemens, GE): ingresos 30000-80000M‚Ç¨, empleados 200000-400000 "
                "- Empresa Grande (10000+ empleados): ingresos 5000-30000M‚Ç¨, empleados 10000-50000 "
                "- Empresa Mediana (1000-10000 empleados): ingresos 500-5000M‚Ç¨, empleados 1000-10000 "
                "- Empresa Peque√±a (<1000 empleados): ingresos 10-500M‚Ç¨, empleados 50-1000 "
                
                "VALORES REQUERIDOS CUANDO NO HAY DATOS CONFIABLES: "
                "- ingresos_anuales_millones_eur: 'N/D' "
                "- empleados_total: 'N/D' "
                "- cuota_mercado_sector_porcentaje: 'N/D' "
                "- gasto_id_porcentaje_ingresos: 'N/D' "
                "- patentes_activas_estimadas: 'N/D' "
                
                "PROHIBICIONES CR√çTICAS: "
                "- NO inventar empresas que no est√©n en COMPETITOR_MAPPING "
                "- NO inventar n√∫meros espec√≠ficos sin base factual s√≥lida "
                "- NO usar rangos (ej: '100-200') - usar n√∫mero espec√≠fico O 'N/D' "
                "- NO incluir Sener o variaciones de Sener "
                "- S√ç usar 'N/D' cuando no tengas datos confiables - ES OBLIGATORIO "
                "- üö´ PROHIBIDO usar textos como: 'An√°lisis comparativo en desarrollo', 'Requiere estudio espec√≠fico', 'Evaluaci√≥n de modelos en proceso' "
                "- üö´ PROHIBIDO usar nombres de empresa placeholder o gen√©ricos - SOLO empresas reales de COMPETITOR_MAPPING "
                
                "RESPONDE SIEMPRE EN ESPA√ëOL CON JSON V√ÅLIDO. USA N√öMEROS ESPEC√çFICOS SOLO SI TIENES DATOS CONFIABLES, SI NO USA 'N/D'."
            ),
            "TECH_IP_LANDSCAPE": (
                "ENFOQUE MEJORADO: Analiza SOLO √°reas tecnol√≥gicas espec√≠ficas de la idea, NO generes contenido gen√©rico. "
                "Si no tienes informaci√≥n espec√≠fica de patentes, enf√≥cate en GAPS y TENDENCIAS basadas en la idea. "
                
                "PRIORIDADES: "
                "1. Identifica GAPS tecnol√≥gicos espec√≠ficos que la idea podr√≠a resolver "
                "2. Analiza TENDENCIAS emergentes relevantes para la idea espec√≠fica "
                "3. SOLO incluye patentes si tienes informaci√≥n espec√≠fica y relevante "
                "4. NO uses frases gen√©ricas como 'tecnolog√≠as del sector' o 'investigaci√≥n relevante' "
                
                "ESTRUCTURA JSON REQUERIDA: "
                
                "1. PATENTES_DESTACADAS (2-4): AN√ÅLISIS T√âCNICO PROFUNDO - usar conocimiento espec√≠fico "
                "BUSCAR EN TU CONOCIMIENTO: patentes de empresas como IBM, Google, Microsoft, Samsung, Siemens, "
                "General Electric, Philips, Sony, etc. relacionadas con la tecnolog√≠a espec√≠fica de la idea. "
                ""
                "Si CONOCES patentes espec√≠ficas: "
                "- titulo: T√≠tulo t√©cnico exacto de la patente conocida "
                "- numero_patente: N√∫mero real de patente (US, EP, WO, etc.) "
                "- titular: Empresa titular espec√≠fica conocida "
                "- a√±o: A√±o de presentaci√≥n/concesi√≥n conocido "
                "- descripcion: Descripci√≥n t√©cnica detallada de la invenci√≥n "
                "- relevancia_competitiva: An√°lisis espec√≠fico de c√≥mo afecta a la idea "
                ""
                "Si NO CONOCES patentes espec√≠ficas: "
                "- titulo: 'B√öSQUEDA ULTRASONIDO: Sistemas anti-biofouling Panasonic/Siemens 40-80 kHz patentes 2018-2024' "
                "- numero_patente: 'GOOGLE PATENTS: keywords ultrasonic biofouling prevention marine surfaces' "
                "- titular: 'EMPRESAS OBJETIVO: Panasonic Corp, Siemens AG, General Electric, Bosch Sensortec' "
                "- descripcion: 'AN√ÅLISIS IP: Transductores piezoel√©ctricos, frecuencias anti-fouling, sistemas bajo consumo' "
                "- relevancia_competitiva: 'CR√çTICA - Libertad operaci√≥n en ultrasonido 40-80 kHz para aplicaciones marinas' "
                
                "2. PUBLICACIONES_CLAVE (2-4): LITERATURA CIENT√çFICA ESPEC√çFICA CON M√ÅXIMO DETALLE T√âCNICO "
                "üî¨ BUSCAR EN TU CONOCIMIENTO PUBLICACIONES REALES: "
                "- Papers espec√≠ficos de Nature, Science, Nature Materials, Science Advances "
                "- IEEE Transactions espec√≠ficos del √°rea (IEEE Trans Ultrasonics, IEEE Trans Marine Tech, etc.) "
                "- Autores RECONOCIDOS espec√≠ficos (ej: Joseph Paradiso del MIT, Daniel Rus del MIT, etc.) "
                "- DOIs espec√≠ficos si los conoces "
                ""
                "‚úÖ SI CONOCES PUBLICACIONES ESPEC√çFICAS REALES (PREFERIDO): "
                "- titulo: '[T√≠tulo exacto del paper que conoces]' "
                "- autores: '[Nombres reales de autores que conoces]' "
                "- revista: '[Revista espec√≠fica: Nature Materials, Science, IEEE Trans X, etc.]' "
                "- a√±o: '[A√±o exacto que conoces]' "
                "- doi: '[DOI espec√≠fico si lo conoces]' "
                "- resumen: '[Resumen t√©cnico de hallazgos espec√≠ficos que conoces]' "
                "- relevancia_tecnologica: '[Impacto espec√≠fico conocido]' "
                "- url: '[URL del DOI o paper si la conoces]' "
                ""
                "üîç SI NO CONOCES PUBLICACIONES ESPEC√çFICAS (M√ÅS PROBABLE): "
                "‚ö†Ô∏è IMPORTANTE: SER MUY ESPEC√çFICO EN B√öSQUEDAS REQUERIDAS: "
                ""
                "EJEMPLO 1 - Literatura sobre frecuencias ultras√≥nicas: "
                "- titulo: 'REVISI√ìN LITERATURA REQUERIDA: Optimizaci√≥n frecuencias ultras√≥nicas 20-80 kHz para control biofouling marino' "
                "- autores: 'INVESTIGACI√ìN NECESARIA: Prof. Joseph Paradiso (MIT Media Lab), equipos de Marine Acoustics Lab MIT, Stanford Ocean Engineering Dept' "
                "- revista: 'B√öSQUEDA OBLIGATORIA: Nature Materials vol 2019-2024, IEEE Transactions on Ultrasonics vol 2020-2024, Applied Physics Letters √∫ltimos n√∫meros' "
                "- a√±o: 'PER√çODO CR√çTICO: 2019-2024 (√∫ltimos 5 a√±os de avances)' "
                "- resumen: 'ESTADO ARTE REQUERIDO: M√©todos de calibraci√≥n frecuencia 40-80 kHz, eficacia contra Pseudomonas aeruginosa, consumo energ√©tico < 10W/m¬≤, durabilidad transductores piezoel√©ctricos' "
                "- relevancia_tecnologica: 'CR√çTICA - Validaci√≥n cient√≠fica par√°metros para dise√±o sistema SENER ultrasonido anti-fouling' "
                "- url: 'https://doi.org/ [b√∫squeda requerida en literatura especializada]' "
                ""
                "EJEMPLO 2 - Literatura sobre materiales avanzados: "
                "- titulo: 'CONSULTA BIBLIOGR√ÅFICA ESPECIALIZADA: Materiales piezoel√©ctricos para transductores marinos alta eficiencia' "
                "- autores: 'EXPERTOS A CONSULTAR: Prof. Yet-Ming Chiang (MIT Materials), investigadores ETH Zurich Soft Robotics Lab, Delft University Marine Technology' "
                "- revista: 'JOURNALS OBJETIVO: Nature Materials, Advanced Materials, Journal of Marine Science and Engineering, IEEE Trans Marine Technology' "
                "- a√±o: 'PUBLICACIONES RECIENTES: 2020-2024' "
                "- resumen: 'CONOCIMIENTO REQUERIDO: Cer√°micas piezoel√©ctricas PZT modificadas, pol√≠meros conductores flexibles, degradaci√≥n por agua salada, temperatura operativa -20¬∞C a +60¬∞C' "
                "- relevancia_tecnologica: 'ALTA - Selecci√≥n materiales para durabilidad 20+ a√±os en ambiente marino' "
                "- url: 'https://doi.org/ [identificar DOIs espec√≠ficos en b√∫squeda dirigida]' "
                ""
                "üö® REQUISITOS DE ESPECIFICIDAD OBLIGATORIOS: "
                "1. FRECUENCIAS ESPEC√çFICAS: Siempre mencionar rangos exactos (ej: 40-80 kHz, no 'frecuencias apropiadas') "
                "2. ORGANISMOS ESPEC√çFICOS: Usar nombres completos (Pseudomonas aeruginosa, no 'microorganismos marinos') "
                "3. UNIVERSIDADES ESPEC√çFICAS: Nombrar labs exactos (MIT Media Lab, no 'centros de investigaci√≥n') "
                "4. REVISTAS ESPEC√çFICAS: T√≠tulos completos (IEEE Trans Ultrasonics, no 'revistas especializadas') "
                "5. PER√çODOS ESPEC√çFICOS: A√±os exactos (2019-2024, no 'per√≠odo reciente') "
                "6. PAR√ÅMETROS T√âCNICOS: Valores cuantificados (< 10W/m¬≤, 20+ a√±os, no 'bajo consumo', 'larga duraci√≥n') "
                
                "3. GAPS_TECNOLOGICOS (2-4): AN√ÅLISIS T√âCNICO ESPEC√çFICO de limitaciones actuales "
                "- area_tecnologica: √Årea t√©cnica espec√≠fica con nomenclatura precisa "
                "- descripcion_gap: Descripci√≥n t√©cnica detallada del vac√≠o o limitaci√≥n "
                "- impacto_competitivo: An√°lisis espec√≠fico de c√≥mo afecta a competidores "
                "- oportunidad_sener: Ventaja competitiva espec√≠fica y cuantificable para SENER "
                "- barreras_tecnicas: Barreras t√©cnicas espec√≠ficas que existen actualmente "
                
                "4. TENDENCIAS_EMERGENTES (2-3): Tendencias tecnol√≥gicas con impacto espec√≠fico "
                "- tecnologia: Tecnolog√≠a emergente con descripci√≥n t√©cnica espec√≠fica "
                "- estado_madurez: TRL (Technology Readiness Level) espec√≠fico o estado detallado "
                "- potencial_disruptivo: An√°lisis cuantitativo del potencial disruptivo "
                "- plazo_adopcion: Timeframe espec√≠fico con justificaci√≥n t√©cnica "
                "- empresas_lideres: Empresas espec√≠ficas que lideran esta tendencia "
                
                "EJEMPLOS ESPEC√çFICOS vs B√öSQUEDA REQUERIDA: "
                
                "EJEMPLOS DE AN√ÅLISIS T√âCNICO PROFUNDO: "
                
                "üö® EJEMPLOS DE FORMATO CORRECTO (SIN INVENTAR DATOS): "
                
                "SI CONOCES PATENTE REAL (poco probable): "
                "titulo: '[T√≠tulo real de patente que conozcas]' "
                "numero_patente: '[N√∫mero real que conozcas]' "
                "titular: '[Empresa real]' "
                
                "SI NO CONOCES PATENTE REAL (m√°s probable - LO NORMAL): "
                "titulo: 'Se requiere b√∫squeda espec√≠fica en tecnolog√≠as ultras√≥nicas para prevenci√≥n de biofouling' "
                "numero_patente: 'B√öSQUEDA REQUERIDA: Google Patents con keywords ultrasonic+biofouling+prevention' "
                "titular: 'INVESTIGACI√ìN NECESARIA: Panasonic Corp, Siemens AG, General Electric, Samsung Electronics' "
                "a√±o: 'PER√çODO B√öSQUEDA: 2018-2024' "
                "descripcion: 'TECNOLOG√çAS A BUSCAR: Transductores piezoel√©ctricos, frecuencias 20-80 kHz, aplicaciones marinas' "
                
                "SI CONOCES PUBLICACI√ìN REAL (poco probable): "
                "titulo: '[T√≠tulo real de art√≠culo que conozcas]' "
                "autores: '[Autores reales]' "
                "revista: '[Journal real]' "
                
                "SI NO CONOCES PUBLICACI√ìN REAL (m√°s probable - LO NORMAL): "
                "titulo: 'Se requiere revisi√≥n bibliogr√°fica en ultrasonido y control de biofouling marino' "
                "autores: 'Investigaci√≥n necesaria en universidades: MIT, Stanford, ETH Zurich, Delft University' "
                "revista: 'B√∫squeda en journals: Nature Materials, Science, IEEE Transactions on Ultrasonics' "
                
                "üö® REGLAS ANTI-GEN√âRICO - CONTENIDO ESPEC√çFICO OBLIGATORIO üö® "
                ""
                "üö® PROHIBICIONES CR√çTICAS - CAUSA RECHAZO AUTOM√ÅTICO: "
                ""
                "‚ùå NUNCA INVENTAR N√öMEROS DE PATENTE: "
                "- NO generes n√∫meros como 'US20190234567A1', 'EP3456789A1', 'US10123456B2' "
                "- Si no conoces el n√∫mero real, usa: 'B√öSQUEDA REQUERIDA: Google Patents + keywords espec√≠ficos' "
                "- SIEMPRE usa indicaciones de b√∫squeda en lugar de n√∫meros inventados "
                ""
                "‚ùå FRASES GEN√âRICAS PROHIBIDAS: "
                "- '√°rea tecnol√≥gica espec√≠fica' ‚Üí Especifica: 'sistemas ultras√≥nicos anti-biofouling' "
                "- 'bases de datos especializadas' ‚Üí Especifica: 'Google Patents, USPTO.gov, EPO.org' "
                "- 'empresas del sector' ‚Üí Especifica: 'Panasonic Corp, Siemens AG, Bosch Sensortec' "
                "- 'universidades del √°rea' ‚Üí Especifica: 'MIT Marine Lab, Stanford Ocean Engineering' "
                "- 'investigadores por identificar' ‚Üí Especifica: 'Research teams at ETH Zurich Bio-interfaces' "
                ""
                "‚úÖ CONTENIDO OBLIGATORIO: "
                "1. PATENTES: SI NO conoces n√∫meros reales, di 'B√∫squeda requerida en Google Patents para [empresa espec√≠fica]' "
                "2. REVISTAS: Nature Materials, Science Advances, IEEE Trans Marine Technology (NO 'revistas especializadas') "
                "3. EMPRESAS: Nombrar espec√≠ficamente Panasonic, Siemens, General Electric, IBM, etc. "
                "4. UNIVERSIDADES: MIT, Stanford, ETH, Delft (NO 'centros de investigaci√≥n del √°rea') "
                "5. FECHAS: 2019-2024, √∫ltimos 5 a√±os (NO 'per√≠odo reciente') "
                "6. FRECUENCIAS: 40-80 kHz espec√≠ficos (NO 'rangos apropiados') "
                
                "FORMATO: JSON v√°lido sin texto adicional. "
                "OBJETIVO: M√°ximo contenido t√©cnico espec√≠fico O b√∫squeda transparente bien dirigida. "
                "PROHIBIDO: Contenido gen√©rico, vago, o datos inventados. "
                "RESPONDE SIEMPRE EN ESPA√ëOL."
            ),
            "MARKET_ANALYSIS": (
                "Extrae datos estructurados del mercado Y genera gaps y oportunidades espec√≠ficas. "
                "Devuelve JSON con la estructura exacta del schema proporcionado. "
                
                "CAMPOS OBLIGATORIOS DEL JSON: "
                "- TAM_2025: Tama√±o del mercado en d√≥lares/euros (n√∫mero) "
                "- CAGR_2025_2030: Tasa de crecimiento anual compuesta (n√∫mero decimal) "
                "- segmentos: Lista de segmentos de mercado espec√≠ficos "
                "- geografias: Lista de regiones/pa√≠ses objetivo "
                "- drivers: Lista de factores que impulsan el crecimiento "
                "- restrictores: Lista de barreras o limitaciones del mercado "
                
                "AN√ÅLISIS CUALITATIVO (CR√çTICO): "
                "- gaps_identificados: Lista de 3-4 vac√≠os espec√≠ficos del mercado actual "
                "- oportunidades_sener: Lista de 3-4 oportunidades espec√≠ficas para Sener "
                
                "EJEMPLO FORMATO gaps_identificados: "
                "[\"Falta de soluciones modulares en hospitales urbanos\", \"Limitada integraci√≥n tecnol√≥gica en infraestructuras\"] "
                
                "EJEMPLO FORMATO oportunidades_sener: "
                "[\"Liderar mercado de hospitales modulares verticales\", \"Aprovechar experiencia en ingenier√≠a para infraestructura sanitaria\"] "
                
                "CRITERIOS: "
                "- Los gaps deben ser necesidades NO cubiertas por competidores actuales "
                "- Las oportunidades deben conectar con capacidades de Sener en ingenier√≠a "
                "- Ser espec√≠ficos y accionables, no gen√©ricos "
                
                "FORMATO: JSON v√°lido sin texto adicional. "
                "ENFOQUE: Datos espec√≠ficos del sector de la idea analizada. "
                "RESPONDE SIEMPRE EN ESPA√ëOL."
            ),
            "SWOT_POSITIONING": (
                "Realiza un an√°lisis DAFO espec√≠fico para la idea analizada en el contexto del mercado y competidores identificados. "
                "Devuelve JSON v√°lido con la estructura exacta especificada. "
                
                "ESTRUCTURA OBLIGATORIA: "
                "{\"swot\":{\"fortalezas\":[\"item1\",\"item2\",\"item3\"],\"debilidades\":[\"item1\",\"item2\",\"item3\"],\"oportunidades\":[\"item1\",\"item2\",\"item3\"],\"amenazas\":[\"item1\",\"item2\",\"item3\"]},"
                "\"mapa_posicionamiento\":{\"eje_x\":\"descripci√≥n del eje X\",\"eje_y\":\"descripci√≥n del eje Y\",\"comentario\":\"posicionamiento de la idea\"}} "
                
                "AN√ÅLISIS DAFO ESPEC√çFICO: "
                
                "1. FORTALEZAS (3-4 elementos): "
                "- Capacidades de Sener que encajan con la idea analizada "
                "- Ventajas t√©cnicas o de mercado espec√≠ficas para esta idea "
                "- Recursos y experiencia aplicables al sector identificado "
                "- Diferenciadores competitivos √∫nicos para esta oportunidad "
                
                "2. DEBILIDADES (3-4 elementos): "
                "- Limitaciones espec√≠ficas para desarrollar esta idea "
                "- Gaps de capacidades o recursos para el sector analizado "
                "- Aspectos donde los competidores identificados tienen ventaja "
                "- Barreras internas para implementar esta soluci√≥n "
                
                "3. OPORTUNIDADES (3-4 elementos): "
                "- Tendencias del mercado que favorecen esta idea espec√≠fica "
                "- Gaps de mercado identificados que la idea puede cubrir "
                "- Sinergias con otros proyectos o l√≠neas de negocio de Sener "
                "- Oportunidades regulatorias o tecnol√≥gicas del sector "
                
                "4. AMENAZAS (3-4 elementos): "
                "- Competidores espec√≠ficos que podr√≠an adelantarse "
                "- Riesgos del sector o mercado identificado "
                "- Barreras regulatorias o tecnol√≥gicas "
                "- Factores que podr√≠an hacer la idea menos viable "
                
                "MAPA DE POSICIONAMIENTO: "
                "- eje_x: Dimensi√≥n competitiva relevante (ej: 'Especializaci√≥n t√©cnica', 'Cobertura geogr√°fica') "
                "- eje_y: Segunda dimensi√≥n estrat√©gica (ej: 'Tama√±o de mercado', 'Grado de innovaci√≥n') "
                "- comentario: Posici√≥n de la idea en este mapa competitivo espec√≠fico "
                
                "CRITERIOS DE CALIDAD: "
                "- Cada elemento debe ser espec√≠fico y relacionado con la idea analizada "
                "- Conectar con los competidores y mercado ya identificados "
                "- Evitar elementos gen√©ricos, ser concreto y accionable "
                "- Si hay informaci√≥n limitada, inferir bas√°ndose en el sector y competidores "
                
                "FORMATO: JSON v√°lido sin texto adicional. "
                "OBLIGATORIO: Siempre incluir exactamente 3-4 elementos por categor√≠a DAFO. "
                "RESPONDE SIEMPRE EN ESPA√ëOL."
            ),
            "REGULATORY_ESG_RISK": (
                "Extrae SOLO datos reales sobre normativas, certificaciones, riesgos regulatorios y oportunidades ESG. "
                "üö® PROHIBIDO INVENTAR: n√∫meros de normativas, c√≥digos de certificaci√≥n, URLs de reguladores "
                "‚úÖ OBLIGATORIO USAR REALES: ISO 9001, ISO 14001, REACH, RoHS, FDA, CE, UL, IEC "
                "‚úÖ ORGANISMOS REALES: Comisi√≥n Europea, EPA, OSHA, FDA, BSI, T√úV, DNV, Lloyd's "
                "‚úÖ Si NO conoces espec√≠fico: 'Se requiere consulta en [organismo espec√≠fico] para [√°rea]' "
                "FORMATO: JSON v√°lido. Incluye fuente URL real si conoces. No redactes, solo datos."
            ),
            "STRATEGIC_ROADMAP": (
                "Extrae SOLO acciones concretas a 90 d√≠as, 12 meses, 36 meses, y KPIs clave. "
                "Incluye responsables, fechas, y si el KPI es medible. No redactes, solo datos."
            ),
            "APPENDIX": (
                "Extrae SOLO glosario de t√©rminos, metodolog√≠a y limitaciones. "
                "El glosario debe definir t√©rminos t√©cnicos o de negocio usados en el informe. "
                "La metodolog√≠a debe explicar brevemente el enfoque seguido. "
                "Las limitaciones deben ser honestas y profesionales. No redactes, solo datos."
            )
        }
        
        # ‚úÖ CRITICAL FIX: Usar prompt espec√≠fico si est√° disponible (para BENCHMARK_MATRIX)
        if section_id == "BENCHMARK_MATRIX" and specific_benchmark_prompt:
            # Usar el prompt espec√≠fico generado con competidores
            instruction = specific_benchmark_prompt
            print(f"‚úÖ [BENCHMARK] Usando prompt espec√≠fico con competidores ({len(specific_benchmark_prompt)} chars)")
        else:
            # Usar instrucciones normales para otras secciones
            instruction = extraction_instructions.get(section_id, "Extrae SOLO datos estructurados seg√∫n el esquema. No redactes.")
            if section_id == "BENCHMARK_MATRIX":
                print(f"‚ö†Ô∏è [BENCHMARK] Usando prompt gen√©rico (no hay competidores espec√≠ficos)")
        
        # A√±adir contexto de patentes reales si est√° disponible
        full_instruction = instruction + real_patents_context
        
        # üÜï NUEVO: PRE-FILTRO INTELIGENTE DE FUENTES ADICIONALES
        relevant_sources = ""
        extra_sources = shared_inputs.get('extra_sources', '')
        
        if section_id == "BENCHMARK_MATRIX":
            print(f"üîçüîçüîç [INTEGRACI√ìN] ===== BENCHMARK_MATRIX EXCLUIDO DEL FILTRO DE FUENTES =====")
            print(f"üîçüîçüîç [INTEGRACI√ìN] Raz√≥n: BENCHMARK_MATRIX se nutre completamente del COMPETITOR_MAPPING")
            print(f"üîçüîçüîç [INTEGRACI√ìN] Las fuentes ya influyeron en COMPETITOR_MAPPING ‚Üí transferencia autom√°tica")
        elif extra_sources and extra_sources.strip():
            print(f"üîçüîçüîç [INTEGRACI√ìN] ===== INTEGRANDO FUENTES EN {section_id} =====")
            print(f"üîçüîçüîç [INTEGRACI√ìN] extra_sources desde shared_inputs: '{extra_sources}'")
            
            idea_brief = shared_inputs.get('idea_brief', '')
            print(f"üîçüîçüîç [INTEGRACI√ìN] idea_brief: '{idea_brief[:100]}...'")
            
            print(f"üîçüîçüîç [INTEGRACI√ìN] üöÄ LLAMANDO A get_relevant_sources_for_section...")
            relevant_sources = self.get_relevant_sources_for_section(section_id, extra_sources, idea_brief)
            
            print(f"üîçüîçüîç [INTEGRACI√ìN] üì• RESULTADO PRE-FILTRO: '{relevant_sources}'")
            
            if relevant_sources:
                print(f"üîçüîçüîç [INTEGRACI√ìN] ‚úÖ FUENTES RELEVANTES ENCONTRADAS - se usar√°n en prompt optimizado")
            else:
                print(f"üîçüîçüîç [INTEGRACI√ìN] ‚ùå NO HAY FUENTES RELEVANTES - continuando sin fuentes adicionales")
        else:
            print(f"üîçüîçüîç [INTEGRACI√ìN] ‚ÑπÔ∏è NO HAY extra_sources en shared_inputs para {section_id}")
        
        # üî• FORZAR PROMPT ESPEC√çFICO PARA BENCHMARK_MATRIX üî•
        if section_id == "BENCHMARK_MATRIX" and specific_benchmark_prompt:
            print(f"üî• [BENCHMARK-FORCE] USANDO PROMPT ESPEC√çFICO COMPLETO EN LUGAR DEL GEN√âRICO")
            prompt = specific_benchmark_prompt
            # A√±adir esquema al final del prompt espec√≠fico
            prompt += f"\n\n== ESQUEMA JSON OBLIGATORIO ==\n{schema}\n== FIN ESQUEMA ==\n\nRESPUESTA: JSON v√°lido sin texto adicional."
        else:
            # üÜï PROMPT OPTIMIZADO PARA FUENTES ADICIONALES
            if relevant_sources and section_id != "BENCHMARK_MATRIX":
                print(f"üîß [PROMPT-OPTIMIZED] Usando prompt optimizado para fuentes adicionales en {section_id}")
                prompt = f"""AN√ÅLISIS COMPETITIVO - {section_id}

üö® FUENTES PRE-APROBADAS POR FILTRO INTELIGENTE: {relevant_sources}

üí° IDEA: {shared_inputs.get('idea_brief', '')}
üéØ SECTOR: {', '.join(shared_inputs.get('sector_keywords', []))}

üìã TAREA: Analiza la secci√≥n {section_id} para la idea.

üî• INSTRUCCIONES OBLIGATORIAS (EL FILTRO YA DETERMIN√ì QUE SON RELEVANTES):
1. **DEBES CONSULTAR Y MENCIONAR** cada fuente de esta lista: {relevant_sources}
2. **PARA CADA FUENTE** incluye al menos una referencia espec√≠fica usando:
   - "Seg√∫n [NOMBRE_FUENTE]..."
   - "Datos de [NOMBRE_FUENTE] indican..."
   - "[NOMBRE_FUENTE] establece que..."
3. **SI UNA FUENTE** no aporta datos espec√≠ficos directos, EXPLICA qu√© tipo de informaci√≥n se esperar√≠a encontrar en ella para esta secci√≥n
4. **PROHIBIDO**: Ignorar las fuentes que ya fueron validadas como relevantes por el filtro inteligente

üìö SECCI√ìN OBLIGATORIA AL FINAL: "üìö Referencias Consultadas:" con:
- Lista de fuentes mencionadas en el an√°lisis
- URL oficial de cada fuente consultada (si la conoces)
- Breve descripci√≥n de qu√© informaci√≥n aport√≥ cada una

‚ö†Ô∏è RECORDATORIO CR√çTICO: El sistema de filtrado inteligente ya valid√≥ que las fuentes {relevant_sources} son relevantes para {section_id}. Por lo tanto, DEBEN aparecer mencionadas en tu an√°lisis de alguna forma.

== ESQUEMA JSON ==
{schema}
== FIN ESQUEMA ==

{full_instruction}

RESPUESTA: JSON v√°lido con m√°ximo detalle de fuentes consultadas."""
            else:
                # Prompt gen√©rico para secciones sin fuentes adicionales
                prompt = f"""
ANALISTA T√âCNICO SENIOR - MISI√ìN: M√ÅXIMO CONTENIDO ESPEC√çFICO

IDEA: "{shared_inputs.get('idea_brief','')}"
KEYWORDS: {json.dumps(shared_inputs.get('sector_keywords', []), ensure_ascii=False)}
SCORE: "{shared_inputs.get('score','')}"

üö® **PROHIBIDO TERMINANTEMENTE - DATOS INVENTADOS:** üö®
‚ùå NUNCA inventes n√∫meros de patentes (US10845123B2, EP3456789A1, etc.)
‚ùå NUNCA inventes URLs ficticias (https://patents.google.com/patent/...)
‚ùå NUNCA inventes DOIs o referencias que no existan
‚ùå NUNCA inventes datos espec√≠ficos como fechas, autores, t√≠tulos exactos
‚ùå NUNCA inventes normativas (ISO 12345:2023, EN 98765, etc.)
‚ùå NUNCA inventes c√≥digos de certificaci√≥n o n√∫meros de regulaci√≥n ficticia

**TAMBI√âN PROHIBIDO - CONTENIDO GEN√âRICO:**
‚ùå "√°rea tecnol√≥gica espec√≠fica" 
‚ùå "Se requiere b√∫squeda especializada"
‚ùå "bases de datos especializadas"
‚ùå "universidades del √°rea"
‚ùå "investigadores por identificar"

**OBLIGATORIO - SOLO DATOS REALES:**
‚úÖ Empresas REALES: Panasonic, Siemens, IBM, Google, Microsoft, Samsung
‚úÖ Universidades REALES: MIT, Stanford, ETH Zurich, Delft University  
‚úÖ Revistas REALES: Nature Materials, Science, IEEE Transactions
‚úÖ Normativas REALES: ISO 9001, ISO 14001, REACH, RoHS, CE, UL, IEC 60601
‚úÖ Organismos REALES: Comisi√≥n Europea, EPA, OSHA, FDA, BSI, T√úV, DNV
‚úÖ Si NO conoces patentes reales, di: "Se requiere b√∫squeda espec√≠fica en Google Patents para empresas [Panasonic/Siemens/etc.]"
‚úÖ Si NO conoces normativas reales, di: "Se requiere consulta en [EPA/Comisi√≥n Europea/FDA] para regulaci√≥n espec√≠fica en [√°rea]"

== ESQUEMA JSON A COMPLETAR ==
{schema}
== FIN ESQUEMA ==

{full_instruction}

RESPUESTA: JSON v√°lido sin texto adicional. M√ÅXIMO detalle t√©cnico espec√≠fico.
"""
        
        # ‚úÖ NUEVA ESTRATEGIA: Configuraci√≥n espec√≠fica para secciones cr√≠ticas
        if section_id == "TECH_IP_LANDSCAPE":
            system_message = (
                "Eres un ANALISTA T√âCNICO SENIOR con amplio conocimiento en patentes y tecnolog√≠a. "
                "MISI√ìN: Buscar en tu conocimiento DATOS ESPEC√çFICOS de patentes, publicaciones cient√≠ficas, gaps y tendencias. "
                ""
                "INSTRUCCIONES CR√çTICAS: "
                "1. **USA CONOCIMIENTO REAL**: Si conoces patentes de IBM, Google, Microsoft, Samsung, Siemens - √öSALAS con n√∫meros reales "
                "2. **SI NO CONOCES**: Especifica EXACTAMENTE qu√© buscar - NO uses frases vagas como '√°rea tecnol√≥gica espec√≠fica' "
                "3. **EJEMPLOS OBLIGATORIOS**: Para ultrasonido menciona Panasonic, Siemens; para electrificaci√≥n menciona ABB, Schneider "
                "4. **UNIVERSIDADES REALES**: MIT, Stanford, ETH Zurich, Delft - NO 'universidades del √°rea' "
                "5. **BASES DE DATOS**: Google Patents, USPTO.gov, EPO.org - NO 'bases especializadas' "
                "6. **REVISTAS REALES**: Nature Materials, IEEE Transactions, Science - NO 'revistas del √°rea' "
                ""
                "FORMATO: JSON v√°lido ESTRICTO sin texto adicional. "
                "OBJETIVO: M√°ximo contenido t√©cnico espec√≠fico conocido."
            )
            temp = 0.1  # Temperatura baja pero no extrema para permitir especificidad
            max_tok = 1500  # Tokens aumentados para permitir m√°s detalle t√©cnico
        elif section_id == "REGULATORY_ESG_RISK":
            system_message = (
                "Eres un ANALISTA REGULATORIO SENIOR con amplio conocimiento en normativas, certificaciones y ESG. "
                "MISI√ìN: Buscar en tu conocimiento DATOS ESPEC√çFICOS de normativas reales, certificaciones existentes, riesgos regulatorios y oportunidades ESG. "
                ""
                "INSTRUCCIONES CR√çTICAS: "
                "1. **USA NORMATIVAS REALES**: ISO 9001, ISO 14001, REACH, RoHS, CE, UL, IEC, FDA 21 CFR - NUNCA inventes c√≥digos "
                "2. **ORGANISMOS REALES**: Comisi√≥n Europea, EPA, OSHA, FDA, BSI, T√úV, DNV, Lloyd's Register - NO 'autoridades competentes' "
                "3. **SI NO CONOCES**: Especifica 'Se requiere consulta en [EPA/Comisi√≥n Europea] para regulaci√≥n espec√≠fica en [√°rea]' "
                "4. **CERTIFICACIONES REALES**: CE, UL, CSA, FCC, ATEX, SIL - NO inventes c√≥digos de certificaci√≥n "
                "5. **URLs REALES**: Solo si conoces la URL oficial real (europa.eu, epa.gov, iso.org) "
                "6. **TRANSPARENCIA TOTAL**: Si no conoces, ser espec√≠fico sobre qu√© consultar y d√≥nde "
                ""
                "FORMATO: JSON v√°lido ESTRICTO sin texto adicional. "
                "OBJETIVO: M√°ximo contenido regulatorio real y espec√≠fico conocido."
            )
            temp = 0.1  # Temperatura baja para m√°xima precisi√≥n regulatoria
            max_tok = 1500  # Tokens aumentados para permitir m√°s detalle regulatorio
        else:
            system_message = "Eres un analista competitivo senior. NUNCA inventes n√∫meros de patente o datos falsos. S√© transparente sobre limitaciones. Devuelve SOLO el JSON v√°lido."
            temp = 0.15
            max_tok = 1400
        
        # üîç LOGGING CR√çTICO ANTES DE LLAMAR AL LLM
        if section_id == "BENCHMARK_MATRIX":
            print(f"üö® [BENCHMARK-LLM] === ENVIANDO PROMPT AL LLM ===")
            print(f"üö® [BENCHMARK-LLM] Prompt length: {len(prompt)} chars")
            print(f"üö® [BENCHMARK-LLM] System message: {system_message[:100]}...")
            print(f"üö® [BENCHMARK-LLM] First 500 chars of prompt: {prompt[:500]}...")
            if 'tabla_comparativa' in prompt:
                print(f"‚úÖ [BENCHMARK-LLM] Prompt contiene 'tabla_comparativa'")
            # Buscar nombres de empresas espec√≠ficas del mapping
            found_mapping_companies = []
            for word in ['Weber', 'Evoqua', 'Bluewater', 'Sonihull', 'AkzoNobel', 'Hempel', 'Trelleborg', 'ClearBlue', 'Marine Electrical']:
                if word in prompt:
                    found_mapping_companies.append(word)
            if found_mapping_companies:
                print(f"üéØ [BENCHMARK-LLM] EMPRESAS DEL MAPPING ENCONTRADAS: {found_mapping_companies}")
            else:
                print(f"‚ö†Ô∏è [BENCHMARK-LLM] NO SE ENCONTRARON EMPRESAS DEL MAPPING EN PROMPT")
            
            if any(word in prompt.lower() for word in ['competidor', 'empresa', 'siemens', 'abb']):
                print(f"‚úÖ [BENCHMARK-LLM] Prompt contiene palabras clave de empresas")
            print(f"üö® [BENCHMARK-LLM] === LLAMANDO A OPENAI ===")
        
        resp = self.openai_client.chat.completions.create(
            model=self.deployment_name,
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": prompt}
            ],
            temperature=temp,
            max_tokens=max_tok,
            response_format={"type": "json_object"}
        )
        
        # üîç LOGGING CR√çTICO DESPU√âS DE RECIBIR RESPUESTA
        if section_id == "BENCHMARK_MATRIX":
            raw_response = resp.choices[0].message.content
            print(f"üö® [BENCHMARK-LLM] === RESPUESTA DEL LLM RECIBIDA ===")
            print(f"üö® [BENCHMARK-LLM] Response length: {len(raw_response)} chars")
            print(f"üö® [BENCHMARK-LLM] First 300 chars: {raw_response[:300]}...")
            if 'tabla_comparativa' in raw_response:
                print(f"‚úÖ [BENCHMARK-LLM] Respuesta contiene 'tabla_comparativa'")
            if 'tabla' in raw_response and 'tabla_comparativa' not in raw_response:
                print(f"‚ö†Ô∏è [BENCHMARK-LLM] Respuesta contiene solo 'tabla' (formato antiguo)")
            
            # Buscar empresas del mapping en la respuesta
            mapping_companies_in_response = []
            for word in ['Weber', 'Evoqua', 'Bluewater', 'Sonihull', 'AkzoNobel', 'Hempel', 'Trelleborg', 'ClearBlue', 'Marine Electrical']:
                if word in raw_response:
                    mapping_companies_in_response.append(word)
            
            # Buscar empresas gen√©ricas en la respuesta
            generic_companies = [name for name in ['Siemens', 'ABB', 'Schneider', 'GE', 'Rockwell', 'Bosch', 'Samsung', 'Panasonic'] if name in raw_response]
            
            if mapping_companies_in_response:
                print(f"üéØ [BENCHMARK-LLM] ¬°√âXITO! EMPRESAS DEL MAPPING EN RESPUESTA: {mapping_companies_in_response}")
            else:
                print(f"‚ùå [BENCHMARK-LLM] FALL√ì: No se encontraron empresas del mapping en respuesta")
            
            if generic_companies:
                print(f"‚ö†Ô∏è [BENCHMARK-LLM] EMPRESAS GEN√âRICAS DETECTADAS: {generic_companies}")
            else:
                print(f"‚úÖ [BENCHMARK-LLM] Sin empresas gen√©ricas en respuesta")
            print(f"üö® [BENCHMARK-LLM] === PROCESANDO JSON ===")
        
        # ‚úÖ MEJORADO: Manejo robusto de JSON con m√∫ltiples estrategias de recuperaci√≥n
        raw_content = resp.choices[0].message.content
        data = self._parse_json_with_fallback(raw_content, section_id)
        
        # ‚úÖ APLICAR VALIDACI√ìN Y FILTRADO AUTOM√ÅTICO PARA COMPETIDORES
        if section_id == "COMPETITOR_MAPPING":
            data = self._validate_and_filter_competitors(data)
            print(f"üîç [CompetitorAnalysis] Competidores validados y filtrados para {section_id}")
        
        # ‚úÖ NUEVA VALIDACI√ìN PARA BENCHMARK_MATRIX - M√âTRICAS CUANTITATIVAS
        if section_id == "BENCHMARK_MATRIX":
            # üîß CONVERSI√ìN CR√çTICA: Convertir formato antiguo a nuevo ANTES de validaci√≥n
            if isinstance(data, dict) and 'tabla' in data and 'tabla_comparativa' not in data:
                print("üîÑ [BENCHMARK] Convirtiendo formato antiguo 'tabla' a 'tabla_comparativa' ANTES de validaci√≥n")
                data['tabla_comparativa'] = data.pop('tabla')
            
            # üéØ NUEVA VALIDACI√ìN ROBUSTA: Verificar coherencia con COMPETITOR_MAPPING
            data = self._validate_benchmark_competitor_coherence(data, report_dict)
            
            # Validar y normalizar m√©tricas cuantitativas
            data = self._validate_benchmark_metrics(data)
            
            # Filtrar Sener y competidores inv√°lidos (mantener compatibilidad con formato anterior)
            if isinstance(data, dict):
                # Nuevo formato: tabla_comparativa
                if 'tabla_comparativa' in data and isinstance(data['tabla_comparativa'], list):
                    tabla_filtrada = []
                    for competidor in data['tabla_comparativa']:
                        if isinstance(competidor, dict):
                            nombre = competidor.get('nombre', '')
                            if nombre and 'sener' not in nombre.lower():
                                tabla_filtrada.append(competidor)
                    data['tabla_comparativa'] = tabla_filtrada
                    print(f"üîç [BENCHMARK] Tabla cuantitativa filtrada: {len(tabla_filtrada)} competidores (Sener excluido)")
                
                # Formato anterior para compatibilidad: tabla
                elif 'tabla' in data and isinstance(data['tabla'], list):
                    tabla_filtrada = []
                    for competidor in data['tabla']:
                        if isinstance(competidor, dict):
                            nombre = competidor.get('nombre', competidor.get('empresa', ''))
                            if nombre and 'sener' not in nombre.lower():
                                tabla_filtrada.append(competidor)
                    data['tabla'] = tabla_filtrada
                    print(f"üîç [BENCHMARK] Tabla formato anterior filtrada: {len(tabla_filtrada)} competidores (Sener excluido)")
        
        # ‚úÖ NUEVA VALIDACI√ìN: Verificar patentes para TECH_IP_LANDSCAPE
        if section_id == "TECH_IP_LANDSCAPE":
            data = self._validate_patent_data(data)
            print(f"üîç [CompetitorAnalysis] Datos de patentes validados para transparencia")
            
            # ‚úÖ NUEVA VALIDACI√ìN: Verificar publicaciones cient√≠ficas
            data = self._validate_publication_data(data)
            print(f"üîç [CompetitorAnalysis] Datos de publicaciones cient√≠ficas validados para especificidad")
        
        # ‚úÖ NUEVA VALIDACI√ìN: Verificar datos regulatorios para REGULATORY_ESG_RISK
        if section_id == "REGULATORY_ESG_RISK":
            data = self._validate_regulatory_data(data)
            print(f"üîç [CompetitorAnalysis] Datos regulatorios validados para transparencia")
        
        # ---------------------------------------------------------------
        # üî• NUEVO: fallback final -> si la tabla qued√≥ vac√≠a o solo contiene
        #            el placeholder gen√©rico, crear una tabla m√≠nima con los
        #            competidores del mapping y m√©tricas 'N/D'.
        if section_id == "BENCHMARK_MATRIX":
            tabla_key = 'tabla_comparativa' if isinstance(data, dict) and 'tabla_comparativa' in data else 'tabla'
            placeholder_strings = [
                'an√°lisis comparativo en desarrollo',
                'requiere estudio espec√≠fico',
                'evaluaci√≥n de modelos en proceso'
            ]
            def _fila_es_placeholder(fila: dict) -> bool:
                nombre = (fila.get('nombre') or '').lower()
                return any(ph in nombre for ph in placeholder_strings)
            tabla_actual = []
            if isinstance(data, dict) and tabla_key in data and isinstance(data[tabla_key], list):
                tabla_actual = [fila for fila in data[tabla_key] if isinstance(fila, dict) and not _fila_es_placeholder(fila)]
            # Si no quedan filas v√°lidas, reconstruir con competidores del mapping
            if not tabla_actual:
                mapping_competitors = []
                if report_dict and 'COMPETITOR_MAPPING' in report_dict:
                    mapping_competitors = [c['nombre'] for c in self._extract_competitors_from_mapping(report_dict)[:7]]
                if mapping_competitors:
                    print("‚ö†Ô∏è [BENCHMARK] Tabla vac√≠a o placeholder: generando versi√≥n m√≠nima con competidores del mapping")
                    tabla_actual = []
                    for comp in mapping_competitors:
                        tabla_actual.append({
                            'nombre': comp,
                            'ingresos_anuales_millones_eur': 'N/D',
                            'empleados_total': 'N/D',
                            'a√±os_en_mercado': 'N/D',
                            'paises_presencia': 'N/D',
                            'proyectos_anuales_estimados': 'N/D',
                            'precio_promedio_proyecto_millones': 'N/D',
                            'cuota_mercado_sector_porcentaje': 'N/D',
                            'gasto_id_porcentaje_ingresos': 'N/D',
                            'certificaciones_principales': 'N/D',
                            'patentes_activas_estimadas': 'N/D'
                        })
                    # Actualizar estructura
                    if isinstance(data, dict):
                        data[tabla_key] = tabla_actual
                    else:
                        data = {tabla_key: tabla_actual}
        # ---------------------------------------------------------------
        
        return data
    
    def _parse_json_with_fallback(self, raw_content, section_id):
        """
        ‚úÖ NUEVA FUNCI√ìN: Parsea JSON con m√∫ltiples estrategias de recuperaci√≥n ante errores
        """
        import re
        
        # Estrategia 1: JSON directo (caso normal)
        try:
            return json.loads(raw_content)
        except json.JSONDecodeError as e:
            print(f"‚ö†Ô∏è [JSON] Estrategia 1 fall√≥ para {section_id}: {e}")
        
        # Estrategia 2: Limpiar comillas sin cerrar y caracteres problem√°ticos
        try:
            # Limpiar posibles problemas comunes de JSON
            cleaned = raw_content.strip()
            
            # Escapar comillas dobles no cerradas dentro de strings
            cleaned = self._fix_unescaped_quotes(cleaned)
            
            # Remover trailing commas
            cleaned = re.sub(r',(\s*[}\]])', r'\1', cleaned)
            
            # Intentar parsear JSON limpio
            return json.loads(cleaned)
        except json.JSONDecodeError as e:
            print(f"‚ö†Ô∏è [JSON] Estrategia 2 fall√≥ para {section_id}: {e}")
        
        # Estrategia 3: Extraer JSON desde el primer { hasta el √∫ltimo }
        try:
            start_idx = raw_content.find('{')
            end_idx = raw_content.rfind('}')
            
            if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
                json_part = raw_content[start_idx:end_idx+1]
                json_part = self._fix_unescaped_quotes(json_part)
                return json.loads(json_part)
        except json.JSONDecodeError as e:
            print(f"‚ö†Ô∏è [JSON] Estrategia 3 fall√≥ para {section_id}: {e}")
        
        # Estrategia 4: Intentar completar JSON incompleto
        try:
            completed_json = self._attempt_json_completion(raw_content)
            if completed_json:
                return json.loads(completed_json)
        except json.JSONDecodeError as e:
            print(f"‚ö†Ô∏è [JSON] Estrategia 4 fall√≥ para {section_id}: {e}")
        
        # Estrategia 5: Para TECH_IP_LANDSCAPE, intentar extraer partes del JSON malformado
        if section_id == "TECH_IP_LANDSCAPE":
            try:
                print(f"üîß [JSON] Estrategia especial para TECH_IP_LANDSCAPE: extracci√≥n parcial")
                # Intentar extraer al menos las partes que se puedan usar
                partial_data = self._extract_partial_tech_landscape(raw_content)
                if partial_data and len(partial_data) > 1:  # Si tiene al menos algunos datos
                    return partial_data
            except Exception as e:
                print(f"‚ö†Ô∏è [JSON] Extracci√≥n parcial fall√≥: {e}")
        
        # Estrategia 6: Fallback a estructura por defecto
        print(f"üîÑ [JSON] Todas las estrategias fallaron para {section_id}, usando estructura por defecto")
        return self._generate_default_structure(section_id)
    
    def _fix_unescaped_quotes(self, json_str):
        """
        ‚úÖ NUEVA FUNCI√ìN: Repara comillas sin cerrar en JSON malformado
        """
        try:
            # Reparar strings sin cerrar al final de l√≠neas
            lines = json_str.split('\n')
            fixed_lines = []
            
            for line in lines:
                # Si la l√≠nea tiene una comilla de apertura pero no de cierre
                if line.count('"') % 2 == 1 and ':' in line:
                    # A√±adir comilla de cierre antes de la coma o fin de l√≠nea
                    if line.rstrip().endswith(','):
                        line = line.rstrip()[:-1] + '",'
                    elif not line.rstrip().endswith('"'):
                        line = line.rstrip() + '"'
                
                fixed_lines.append(line)
            
            return '\n'.join(fixed_lines)
        except Exception:
            return json_str
    
    def _attempt_json_completion(self, raw_content):
        """
        ‚úÖ NUEVA FUNCI√ìN: Intenta completar JSON incompleto
        """
        try:
            # Encontrar la estructura JSON principal
            start_idx = raw_content.find('{')
            if start_idx == -1:
                return None
            
            # Contar llaves para determinar si est√° completo
            open_braces = 0
            close_braces = 0
            last_valid_idx = start_idx
            
            for i, char in enumerate(raw_content[start_idx:], start_idx):
                if char == '{':
                    open_braces += 1
                elif char == '}':
                    close_braces += 1
                    last_valid_idx = i
                
                # Si las llaves est√°n balanceadas, tenemos JSON completo
                if open_braces > 0 and open_braces == close_braces:
                    return raw_content[start_idx:i+1]
            
            # Si no est√°n balanceadas, intentar completar
            if open_braces > close_braces:
                missing_braces = open_braces - close_braces
                completion = raw_content[start_idx:last_valid_idx+1] + ('}' * missing_braces)
                return completion
            
            return None
        except Exception:
            return None
    
    def _extract_partial_tech_landscape(self, raw_content):
        """
        ‚úÖ NUEVA FUNCI√ìN: Extrae datos parciales de TECH_IP_LANDSCAPE cuando JSON est√° malformado
        """
        try:
            import re
            
            # Estructura base
            result = {
                "patentes_destacadas": [],
                "publicaciones_clave": [],
                "gaps_tecnologicos": [],
                "tendencias_emergentes": []
            }
            
            # Buscar patentes con regex
            patent_pattern = r'"titulo":\s*"([^"]*)".*?"numero_patente":\s*"([^"]*)".*?"titular":\s*"([^"]*)"'
            patents = re.findall(patent_pattern, raw_content, re.DOTALL)
            
            for titulo, numero, titular in patents[:3]:  # Max 3 patentes
                if titulo and numero and titular:
                    result["patentes_destacadas"].append({
                        "titulo": titulo,
                        "numero_patente": numero,
                        "titular": titular,
                        "a√±o": "N/D",
                        "pais": "N/D",
                        "descripcion": "Extra√≠do de respuesta parcial",
                        "relevancia_competitiva": "Media",
                        "url": ""
                    })
            
            # Buscar publicaciones con regex
            pub_pattern = r'"titulo":\s*"([^"]*)".*?"autores":\s*"([^"]*)".*?"revista":\s*"([^"]*)"'
            publications = re.findall(pub_pattern, raw_content, re.DOTALL)
            
            for titulo, autores, revista in publications[:3]:  # Max 3 publicaciones
                if titulo and autores and revista:
                    result["publicaciones_clave"].append({
                        "titulo": titulo,
                        "autores": autores,
                        "revista": revista,
                        "a√±o": "N/D",
                        "tipo": "Art√≠culo",
                        "resumen": "Extra√≠do de respuesta parcial",
                        "relevancia_tecnologica": "Media",
                        "url": ""
                    })
            
            return result if result["patentes_destacadas"] or result["publicaciones_clave"] else None
            
        except Exception:
            return None

    def _validate_patent_data(self, patent_data):
        """
        Valida y mejora la transparencia de los datos de patentes.
        ‚úÖ FUNCI√ìN MEJORADA: Detecta mejor datos inventados y los reemplaza con indicaciones de b√∫squeda
        """
        if not isinstance(patent_data, dict):
            return patent_data
        
        # Validar patentes destacadas
        if 'patentes_destacadas' in patent_data:
            validated_patents = []
            for patent in patent_data['patentes_destacadas']:
                if isinstance(patent, dict):
                    # Verificar n√∫meros de patente inventados
                    numero = patent.get('numero_patente', '')
                    if numero and self._looks_like_fake_patent_number(numero):
                        # Reemplazar con b√∫squeda espec√≠fica usando el formato de las instrucciones
                        titulo = patent.get('titulo', 'tecnolog√≠a espec√≠fica')
                        keywords = titulo.split()[:3]  # Primeras 3 palabras del t√≠tulo
                        keyword_str = '+'.join(keywords) if keywords else 'keywords+espec√≠ficos'
                        patent['numero_patente'] = f'B√öSQUEDA REQUERIDA: Google Patents con keywords {keyword_str}'
                        
                        # Tambi√©n actualizar URL si existe
                        if patent.get('url', '').startswith('https://patents.google.com/patent/'):
                            patent['url'] = 'Disponible en Google Patents tras b√∫squeda espec√≠fica con keywords t√©cnicos'
                    
                    # Validar DOIs inventados (formato: 10.xxxx/...)
                    doi = patent.get('doi', '')
                    if doi and doi.startswith('10.') and len(doi) > 20:
                        # Si parece un DOI muy espec√≠fico, probablemente inventado
                        patent['doi'] = 'DOI disponible tras b√∫squeda espec√≠fica'
                    
                    validated_patents.append(patent)
            
            patent_data['patentes_destacadas'] = validated_patents
        
        return patent_data
    
    def _validate_regulatory_data(self, regulatory_data):
        """
        Valida y mejora la transparencia de los datos regulatorios.
        ‚úÖ FUNCI√ìN NUEVA: Detecta normativas inventadas y mejora transparencia
        """
        if not isinstance(regulatory_data, dict):
            return regulatory_data
        
        # Validar normativas clave
        if 'normativas_clave' in regulatory_data:
            validated_normativas = []
            for normativa in regulatory_data['normativas_clave']:
                if isinstance(normativa, dict):
                    # Verificar si parece una normativa inventada
                    nombre = normativa.get('nombre', '')
                    if nombre and self._looks_like_fake_regulation(nombre):
                        # Reemplazar con indicaci√≥n transparente
                        normativa_transparente = {
                            **normativa,
                            'nombre': f"Se requiere consulta en Comisi√≥n Europea/EPA para regulaci√≥n espec√≠fica en {normativa.get('√°rea', '√°rea aplicable')}",
                            'detalle': f"Verificaci√≥n pendiente de regulaciones aplicables en {normativa.get('√°rea', 'el sector')}"
                        }
                        validated_normativas.append(normativa_transparente)
                    else:
                        validated_normativas.append(normativa)
                elif isinstance(normativa, str):
                    if self._looks_like_fake_regulation(normativa):
                        validated_normativas.append(f"Se requiere consulta regulatoria espec√≠fica para: {normativa}")
                    else:
                        validated_normativas.append(normativa)
            
            regulatory_data['normativas_clave'] = validated_normativas
        
        # Validar certificaciones
        if 'certificaciones' in regulatory_data:
            validated_certificaciones = []
            for cert in regulatory_data['certificaciones']:
                if isinstance(cert, dict):
                    nombre = cert.get('nombre', '')
                    if nombre and self._looks_like_fake_certification(nombre):
                        cert_transparente = {
                            **cert,
                            'nombre': f"Se requiere consulta en BSI/T√úV/DNV para certificaci√≥n espec√≠fica en {cert.get('√°rea', '√°rea aplicable')}",
                            'detalle': f"Verificaci√≥n pendiente de certificaciones requeridas en {cert.get('√°rea', 'el sector')}"
                        }
                        validated_certificaciones.append(cert_transparente)
                    else:
                        validated_certificaciones.append(cert)
                elif isinstance(cert, str):
                    if self._looks_like_fake_certification(cert):
                        validated_certificaciones.append(f"Se requiere consulta para certificaci√≥n: {cert}")
                    else:
                        validated_certificaciones.append(cert)
            
            regulatory_data['certificaciones'] = validated_certificaciones
        
        return regulatory_data
    
    def _validate_publication_data(self, publication_data):
        """
        Valida y mejora la transparencia de los datos de publicaciones cient√≠ficas.
        ‚úÖ FUNCI√ìN NUEVA: Detecta publicaciones inventadas y mejora especificidad
        """
        if not isinstance(publication_data, dict):
            return publication_data
        
        # Validar publicaciones clave
        if 'publicaciones_clave' in publication_data:
            validated_publications = []
            for pub in publication_data['publicaciones_clave']:
                if isinstance(pub, dict):
                    # Verificar t√≠tulos gen√©ricos o inventados
                    titulo = pub.get('titulo', '')
                    if titulo and self._looks_like_fake_publication_title(titulo):
                        # Reemplazar con b√∫squeda espec√≠fica basada en el √°rea
                        area_keyword = pub.get('resumen', '').split()[:3]  # Primeras palabras del resumen
                        area_keyword = ' '.join(area_keyword) if area_keyword else '√°rea tecnol√≥gica'
                        
                        pub['titulo'] = f"REVISI√ìN LITERATURA REQUERIDA: An√°lisis bibliogr√°fico especializado en {area_keyword}"
                    
                    # Verificar autores gen√©ricos
                    autores = pub.get('autores', '')
                    if autores and self._looks_like_fake_authors(autores):
                        # Reemplazar con instituciones espec√≠ficas de b√∫squeda
                        pub['autores'] = 'INVESTIGACI√ìN NECESARIA: Equipos MIT, Stanford Engineering, ETH Zurich, Delft University, Cambridge'
                    
                    # Verificar revistas gen√©ricas
                    revista = pub.get('revista', '')
                    if revista and self._looks_like_fake_journal(revista):
                        # Reemplazar con revistas espec√≠ficas del √°rea
                        pub['revista'] = 'B√öSQUEDA OBLIGATORIA: Nature Materials, Science Advances, IEEE Transactions espec√≠ficas del √°rea'
                    
                    # Verificar DOIs inventados
                    doi = pub.get('doi', '')
                    if doi and self._looks_like_fake_doi(doi):
                        pub['doi'] = 'DOI espec√≠fico requerido tras b√∫squeda bibliogr√°fica dirigida'
                    
                    # Verificar URLs inventadas
                    url = pub.get('url', '')
                    if url and self._looks_like_fake_publication_url(url):
                        pub['url'] = 'URL disponible tras identificaci√≥n espec√≠fica en bases bibliogr√°ficas'
                    
                    validated_publications.append(pub)
            
            publication_data['publicaciones_clave'] = validated_publications
        
        return publication_data
    
    def _looks_like_fake_publication_title(self, title):
        """
        Detecta t√≠tulos de publicaciones que parecen inventados o demasiado gen√©ricos.
        """
        title_lower = title.lower()
        
        # Frases gen√©ricas t√≠picas de t√≠tulos inventados
        generic_phrases = [
            'an√°lisis del estado del arte',
            'revisi√≥n de literatura',
            'estudio del √°rea',
            'investigaci√≥n en el campo',
            'advances in',
            'research in',
            'study of',
            'analysis of',
            'development of',
            'investigation into'
        ]
        
        # Detectar t√≠tulos muy gen√©ricos
        for phrase in generic_phrases:
            if phrase in title_lower and len(title) < 100:  # T√≠tulos cortos y gen√©ricos
                return True
        
        # Detectar patrones de t√≠tulos inventados
        import re
        if re.search(r'^(study|analysis|research|investigation)\s+(of|on|in)\s+\w+$', title_lower):
            return True
        
        return False
    
    def _looks_like_fake_authors(self, authors):
        """
        Detecta listas de autores que parecen inventadas.
        """
        authors_lower = authors.lower()
        
        # Frases gen√©ricas t√≠picas de autores inventados
        generic_phrases = [
            'et al.',
            'y colaboradores',
            'equipo de investigaci√≥n',
            'grupo de',
            'investigadores de',
            'equipo del',
            'por determinar',
            'autores varios'
        ]
        
        # Detectar frases gen√©ricas de autores
        for phrase in generic_phrases:
            if phrase in authors_lower and len(authors) < 50:  # Autores cortos y gen√©ricos
                return True
        
        return False
    
    def _looks_like_fake_journal(self, journal):
        """
        Detecta nombres de revistas que parecen inventados o demasiado gen√©ricos.
        """
        journal_lower = journal.lower()
        
        # Frases gen√©ricas de revistas inventadas
        generic_phrases = [
            'journal of',
            'revista de',
            'international journal',
            'revista internacional',
            'proceedings of',
            'revista especializada',
            'revista del √°rea',
            'journal especializado'
        ]
        
        # Solo detectar si es MUY gen√©rico (sin especificidad real)
        generic_count = sum(1 for phrase in generic_phrases if phrase in journal_lower)
        
        # Es gen√©rico si tiene frases gen√©ricas Y es muy corto (falta especificidad)
        if generic_count > 0 and len(journal) < 40:
            return True
        
        return False
    
    def _looks_like_fake_doi(self, doi):
        """
        Detecta DOIs que parecen inventados.
        """
        import re
        
        # Patr√≥n b√°sico de DOI real: 10.xxxx/yyyy
        if not re.match(r'^10\.\d{4}/.*', doi):
            return False  # No es un DOI v√°lido, pero no necesariamente inventado
        
        # Detectar DOIs con patrones sospechosos (muy largos o muy simples)
        if len(doi) > 80:  # DOIs excesivamente largos
            return True
        
        # Detectar patrones de n√∫meros secuenciales (10.1234/123456)
        if re.search(r'10\.\d{4}/\d{6,}$', doi):
            return True
        
        return False
    
    def _looks_like_fake_publication_url(self, url):
        """
        Detecta URLs de publicaciones que parecen inventadas.
        """
        url_lower = url.lower()
        
        # URLs claramente inventadas
        fake_patterns = [
            'example.com',
            'placeholder.org',
            'tempurl.com',
            'arxiv.org/fake',
            'doi.org/fake'
        ]
        
        for pattern in fake_patterns:
            if pattern in url_lower:
                return True
        
        return False
    
    def _looks_like_fake_regulation(self, regulation_name):
        """
        Detecta SOLO normativas que claramente parecen inventadas.
        ‚úÖ FUNCI√ìN NUEVA: M√°s selectiva, solo detecta patrones claramente falsos
        """
        import re
        
        # Patrones sospechosos de normativas inventadas
        fake_patterns = [
            r'ISO \d{5,}:\d{4}',  # ISO con n√∫meros muy largos (ISO 12345:2023)
            r'EN \d{5,}',         # EN con n√∫meros muy largos
            r'IEC \d{5,}',        # IEC con n√∫meros muy largos
            r'ASTM [A-Z]\d{4,}',  # ASTM con n√∫meros muy largos
            r'BS \d{5,}',         # BS con n√∫meros muy largos
            r'DIN \d{5,}',        # DIN con n√∫meros muy largos
        ]
        
        # Tambi√©n detectar frases gen√©ricas
        generic_phrases = [
            'normativa espec√≠fica del sector',
            'regulaci√≥n aplicable',
            'est√°ndar del √°rea',
            'certificaci√≥n requerida',
            'normativas por determinar'
        ]
        
        regulation_lower = regulation_name.lower()
        
        # Verificar patrones sospechosos
        for pattern in fake_patterns:
            if re.search(pattern, regulation_name):
                return True
        
        # Verificar frases gen√©ricas
        for phrase in generic_phrases:
            if phrase in regulation_lower:
                return True
        
        return False
    
    def _looks_like_fake_certification(self, cert_name):
        """
        Detecta certificaciones que parecen inventadas.
        """
        import re
        
        # Patrones sospechosos de certificaciones inventadas
        fake_patterns = [
            r'[A-Z]{2,4}-\d{4,}',   # C√≥digos inventados tipo ABC-1234
            r'CERT\d{4,}',          # CERT1234
            r'[A-Z]{3,}\d{3,}',     # C√≥digos largos tipo XYZ123
        ]
        
        # Frases gen√©ricas
        generic_phrases = [
            'certificaci√≥n espec√≠fica',
            'certificaci√≥n aplicable',
            'certificaci√≥n del sector',
            'certificaci√≥n requerida',
            'por determinar'
        ]
        
        cert_lower = cert_name.lower()
        
        # Verificar patrones sospechosos
        for pattern in fake_patterns:
            if re.search(pattern, cert_name):
                return True
        
        # Verificar frases gen√©ricas
        for phrase in generic_phrases:
            if phrase in cert_lower:
                return True
        
        return False
    
    def _looks_like_fake_patent_number(self, patent_number):
        """
        Detecta n√∫meros de patente que parecen inventados.
        ‚úÖ FUNCI√ìN MEJORADA: Detecta patrones sospechosos MUCHO m√°s agresiva
        """
        import re
        
        if not patent_number or not isinstance(patent_number, str):
            return False
        
        # üö® REGLA PRINCIPAL: Si el LLM genera CUALQUIER n√∫mero de patente espec√≠fico,
        # probablemente lo est√° inventando porque no tiene acceso a bases de datos reales
        
        # Lista ampliada de n√∫meros de patente claramente inventados
        known_fake_patents = [
            'US10845123B2', 'EP3456789A1', 'US10234567B2', 'EP3456789A1', 
            'US10557234B2', 'CN123456789A', 'US10123456B2', 'EP1234567A1', 
            'JP2020123456A', 'US20190234567A1', 'US20200123456A1', 'EP3789456A1',
            'US10998877B2', 'US11123456B2', 'WO2020123456A1', 'CN111234567A'
        ]
        
        if patent_number in known_fake_patents:
            return True
        
        # üö® NUEVA ESTRATEGIA: RECHAZAR CASI TODOS LOS N√öMEROS ESPEC√çFICOS
        # Patrones comunes de n√∫meros inventados (muy amplio)
        common_fake_patterns = [
            r'^US\d{8}[AB]\d$',        # US + 8 d√≠gitos + A/B + d√≠gito
            r'^US\d{11}[AB]\d$',       # US + 11 d√≠gitos + A/B + d√≠gito  
            r'^EP\d{7}[AB]\d$',        # EP + 7 d√≠gitos + A/B + d√≠gito
            r'^CN\d{9}[AB]?$',         # CN + 9 d√≠gitos + opcional A/B
            r'^WO\d{4}\d{6}[AB]\d$',   # WO + a√±o + 6 d√≠gitos + A/B + d√≠gito
            r'^JP\d{4}\d{6}[AB]?$',    # JP + a√±o + 6 d√≠gitos + opcional A/B
            r'^US202[0-4]\d{6}A1$',    # US + a√±o 2020-2024 + 6 d√≠gitos + A1
            r'^US1[01]\d{6}B2$',       # US + 1 + otro d√≠gito + 6 d√≠gitos + B2
        ]
        
        # Si coincide con cualquier patr√≥n com√∫n, analizarlo m√°s
        for pattern in common_fake_patterns:
            if re.match(pattern, patent_number):
                
                # Extraer TODOS los d√≠gitos para an√°lisis
                all_digits = ''.join(re.findall(r'\d', patent_number))
                
                if len(all_digits) >= 6:
                    # Detectar patrones artificiales M√öLTIPLES
                    
                    # 1. Secuencias ascendentes/descendentes
                    consecutive_ascending = 0
                    consecutive_descending = 0
                    for i in range(len(all_digits) - 1):
                        if int(all_digits[i+1]) == int(all_digits[i]) + 1:
                            consecutive_ascending += 1
                        if int(all_digits[i+1]) == int(all_digits[i]) - 1:
                            consecutive_descending += 1
                    
                    # 2. D√≠gitos repetidos
                    unique_digits = len(set(all_digits))
                    digit_diversity = unique_digits / len(all_digits)
                    
                    # 3. Secuencias num√©ricas obvias
                    obvious_sequences = [
                        '123456', '234567', '345678', '456789', '567890',
                        '654321', '987654', '876543', '765432',
                        '111111', '222222', '333333', '444444', '555555',
                        '000000', '123123', '456456', '789789'
                    ]
                    has_obvious_sequence = any(seq in all_digits for seq in obvious_sequences)
                    
                    # 4. A√±os en el n√∫mero que no tienen sentido
                    suspicious_years = ['2019', '2020', '2021', '2022', '2023', '2024']
                    has_recent_year = any(year in patent_number for year in suspicious_years)
                    
                    # üö® CRITERIOS MUY AGRESIVOS PARA DETECTAR INVENTOS:
                    # Si tiene 3+ d√≠gitos consecutivos ascendentes/descendentes
                    if consecutive_ascending >= 3 or consecutive_descending >= 3:
                        return True
                    
                    # Si tiene muy poca diversidad de d√≠gitos (menos de 50%)
                    if digit_diversity < 0.5:
                        return True
                    
                    # Si contiene secuencias obvias
                    if has_obvious_sequence:
                        return True
                    
                    # Si contiene a√±os recientes en posiciones sospechosas
                    if has_recent_year and len(all_digits) >= 8:
                        return True
                    
                    # üö® NUEVA REGLA: N√∫meros "demasiado perfectos"
                    # Si los √∫ltimos 6 d√≠gitos forman patrones
                    if len(all_digits) >= 6:
                        last_6 = all_digits[-6:]
                        # N√∫meros "redondos" o repetitivos
                        if last_6 in ['123456', '234567', '345678', '456789', '567890', 
                                     '111111', '222222', '333333', '444444', '555555', '666666',
                                     '777777', '888888', '999999', '000000', '123123', '456456']:
                            return True
        
        # üö® REGLA ADICIONAL: Si contiene ciertos indicadores de invenci√≥n
        invention_indicators = [
            'example', 'sample', 'test', 'placeholder', 'temp', 'fake', 'demo'
        ]
        
        patent_lower = patent_number.lower()
        if any(indicator in patent_lower for indicator in invention_indicators):
            return True
            
        return False

    def _search_real_patents(self, sector_keywords, max_results=3):
        """
        Busca patentes reales relacionadas con las palabras clave del sector.
        ‚úÖ NUEVA FUNCI√ìN: B√∫squeda real de patentes para evitar datos inventados
        """
        import requests
        import re
        from bs4 import BeautifulSoup
        import logging
        
        try:
            # Construir query de b√∫squeda para patentes
            if isinstance(sector_keywords, list):
                query_terms = " ".join(sector_keywords[:3])  # Usar m√°ximo 3 keywords
            else:
                query_terms = str(sector_keywords)
            
            # Buscar en Google Patents usando requests
            search_url = "https://patents.google.com/xhr/query"
            params = {
                'url': f"q={query_terms}",
                'num': max_results,
                'sort': 'new'  # Patentes m√°s nuevas primero
            }
            
            logging.info(f"[Patents] üîç Buscando patentes reales para: {query_terms}")
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            response = requests.get(search_url, params=params, headers=headers, timeout=10)
            
            if response.status_code == 200:
                try:
                    data = response.json()
                    patents = []
                    
                    # Extraer informaci√≥n de patentes reales
                    if 'results' in data and 'cluster' in data['results']:
                        for cluster in data['results']['cluster']:
                            if 'result' in cluster:
                                for result in cluster['result']:
                                    patent_info = self._extract_patent_info(result)
                                    if patent_info:
                                        patents.append(patent_info)
                                        if len(patents) >= max_results:
                                            break
                            if len(patents) >= max_results:
                                break
                    
                    logging.info(f"[Patents] ‚úÖ Encontradas {len(patents)} patentes reales")
                    return patents
                    
                except Exception as e:
                    logging.warning(f"[Patents] ‚ö†Ô∏è Error procesando respuesta de Google Patents: {e}")
                    return []
            else:
                logging.warning(f"[Patents] ‚ö†Ô∏è Error en b√∫squeda de patentes: HTTP {response.status_code}")
                return []
                
        except Exception as e:
            logging.error(f"[Patents] ‚ùå Error en b√∫squeda real de patentes: {e}")
            return []

    def analyze_ideas_batch_competitor(self, ideas_list, context="", extra_sources="", max_workers=4):
        """
        Analiza una lista de ideas en paralelo usando ThreadPoolExecutor.
        Devuelve un dict con 'ideas' (an√°lisis individuales sin EXEC_SUMMARY) y 'executive_summary' (resumen global).
        """
        from concurrent.futures import ThreadPoolExecutor, as_completed
        
        print(f"üü¢ [CompetitorAnalysis] Iniciando an√°lisis batch de {len(ideas_list)} ideas...")
        
        # 1. Analizar cada idea individualmente (SIN EXEC_SUMMARY)
        results = {}
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_idx = {
                executor.submit(self._analyze_idea_without_exec_summary, idea, context, extra_sources): idx
                for idx, idea in enumerate(ideas_list)
            }
            for future in as_completed(future_to_idx):
                idx = future_to_idx[future]
                try:
                    result = future.result()
                except Exception as e:
                    result = {"error": str(e)}
                results[idx] = result
        
        # Ordenar resultados
        ideas_analyzed = [results[i] for i in range(len(ideas_list))]
        
        # 2. Generar resumen ejecutivo GLOBAL
        print("üü¢ [CompetitorAnalysis] Generando resumen ejecutivo global...")
        global_summary = self._generate_global_executive_summary(ideas_list, ideas_analyzed, context)
        
        return {
            'ideas': ideas_analyzed,
            'executive_summary': global_summary,
            'total_ideas': len(ideas_list),
            'context': context
        }

    def _analyze_idea_without_exec_summary(self, idea, context, extra_sources=""):
        """
        Analiza una idea individual SIN generar resumen ejecutivo (ser√° global).
        """
        try:
            # Usar el an√°lisis existente pero excluir EXEC_SUMMARY
            meta = {'score': idea.get('score', 0)} if isinstance(idea, dict) else {'score': 0}
            full_analysis = self.generate_ai_only_competition_report(idea, context, meta, extra_sources)
            
            # Remover EXEC_SUMMARY si existe
            if 'EXEC_SUMMARY' in full_analysis:
                del full_analysis['EXEC_SUMMARY']
            
            # A√±adir t√≠tulo de la idea para referencia y datos originales
            idea_text = idea.get('idea') if isinstance(idea, dict) and 'idea' in idea else str(idea)
            title = idea.get('title', '') if isinstance(idea, dict) else ''
            if not title and idea_text:
                # üîß EXTRAER T√çTULO CON LIMPIEZA MEJORADA
                first_line = idea_text.split('\n')[0].strip()
                import re
                
                # Paso 1: Limpiar patrones duplicados como "Idea 1: Idea 1:"
                cleaned_line = re.sub(r'^(idea\s*\d*[\.:]\s*){2,}', '', first_line, flags=re.IGNORECASE)
                
                # Paso 2: Limpiar un prefijo simple "Idea X:" si queda
                cleaned_line = re.sub(r'^idea\s*\d*[\.:]\s*', '', cleaned_line, flags=re.IGNORECASE)
                
                # Paso 3: Limpiar espacios extra
                cleaned_line = cleaned_line.strip()
                
                if len(cleaned_line) > 10:
                    title = cleaned_line[:100] + ('...' if len(cleaned_line) > 100 else '')
                else:
                    # Si la primera l√≠nea es muy corta, tomar m√°s palabras pero limpias
                    full_text_clean = re.sub(r'\b(idea\s*\d*[\.:]\s*){1,}', '', idea_text, flags=re.IGNORECASE)
                    words = full_text_clean.split()[:10]
                    title = ' '.join(words).strip()
                    if len(title) > 100:
                        title = title[:100] + '...'
            
            full_analysis['idea_title'] = title
            full_analysis['idea_text'] = idea_text
            full_analysis['original_idea_data'] = idea  # Preservar datos originales
            
            return full_analysis
            
        except Exception as e:
            print(f"‚ùå Error analizando idea individual: {str(e)}")
            import traceback
            traceback.print_exc()
            return {"error": str(e)}

    def _generate_global_executive_summary(self, ideas_list, ideas_analyzed, context):
        """
        Genera un resumen ejecutivo global para todas las ideas analizadas.
        """
        try:
            # Preparar informaci√≥n de todas las ideas para el resumen global
            ideas_info = []
            
            for i, (idea_original, idea_analysis) in enumerate(zip(ideas_list, ideas_analyzed), 1):
                idea_text = idea_original.get('idea') if isinstance(idea_original, dict) and 'idea' in idea_original else str(idea_original)
                title = idea_original.get('title', '') if isinstance(idea_original, dict) else ''
                
                if not title and idea_text:
                    # üîß EXTRAER T√çTULO CON LIMPIEZA MEJORADA (para resumen ejecutivo)
                    first_line = idea_text.split('\n')[0].strip()
                    import re
                    
                    # Paso 1: Limpiar patrones duplicados como "Idea 1: Idea 1:"
                    cleaned_line = re.sub(r'^(idea\s*\d*[\.:]\s*){2,}', '', first_line, flags=re.IGNORECASE)
                    
                    # Paso 2: Limpiar un prefijo simple "Idea X:" si queda
                    cleaned_line = re.sub(r'^idea\s*\d*[\.:]\s*', '', cleaned_line, flags=re.IGNORECASE)
                    
                    # Paso 3: Limpiar espacios extra
                    cleaned_line = cleaned_line.strip()
                    
                    if len(cleaned_line) > 10:
                        title = cleaned_line[:80] + ('...' if len(cleaned_line) > 80 else '')
                    else:
                        # Si la primera l√≠nea es muy corta, tomar m√°s palabras pero limpias
                        full_text_clean = re.sub(r'\b(idea\s*\d*[\.:]\s*){1,}', '', idea_text, flags=re.IGNORECASE)
                        words = full_text_clean.split()[:10]
                        title = ' '.join(words).strip()
                        if len(title) > 80:
                            title = title[:80] + '...'
                
                ideas_info.append({
                    'numero': i,
                    'titulo': title,
                    'idea': idea_text[:300] + ('...' if len(idea_text) > 300 else ''),
                    'analysis': idea_analysis
                })
            
            # Crear prompt para resumen ejecutivo global
            ideas_summary = "\n\n".join([
                f"IDEA {info['numero']}: {info['titulo']}\n{info['idea']}"
                for info in ideas_info
            ])
            
            user_context = (context or "").strip()
            if user_context:
                contexto_usuario = self.SENER_CONTEXT + "\n\n" + user_context
            else:
                contexto_usuario = self.SENER_CONTEXT
            
            prompt = f"""
            Genera un resumen ejecutivo CORTO Y DIRECTO para el an√°lisis competitivo de {len(ideas_list)} ideas innovadoras.

            CONTEXTO DE SENER:
            {contexto_usuario}

            IDEAS ANALIZADAS:
            {ideas_summary}

            INSTRUCCIONES ESTRICTAS:
            - M√ÅXIMO 300 palabras total
            - M√°ximo 3 p√°rrafos cortos y concisos
            - Ve DIRECTO al grano, sin relleno
            - Incluye SOLO los insights m√°s importantes
            - NO repitas informaci√≥n de an√°lisis individuales
            - Lenguaje ejecutivo: claro, decisivo, accionable

            ESTRUCTURA OBLIGATORIA:
            1. P√°rrafo 1 (100 palabras): Evaluaci√≥n general del portafolio - ¬øQu√© representan estas ideas para Sener?
            2. P√°rrafo 2 (100 palabras): Oportunidades competitivas principales y posicionamiento estrat√©gico
            3. P√°rrafo 3 (100 palabras): Recomendaciones ejecutivas inmediatas y pr√≥ximos pasos cr√≠ticos

            Enf√≥cate en decisiones ejecutivas, no en an√°lisis descriptivo.
            No empieces con "Resumen Ejecutivo: ..."
            """
            
            response = self.openai_client.chat.completions.create(
                model=self.deployment_name,
                messages=[
                    {"role": "system", "content": "Eres un consultor estrat√©gico senior especializado en an√°lisis competitivo y estrategia corporativa. Siempre eres conciso y directo."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=500
            )
            
            global_summary = response.choices[0].message.content.strip()
            
            print("‚úÖ [CompetitorAnalysis] Resumen ejecutivo global generado correctamente")
            
            return {
                'texto': global_summary,
                'total_ideas': len(ideas_list),
                'fecha_generacion': datetime.now().isoformat()
            }
            
        except Exception as e:
            print(f"‚ùå Error generando resumen ejecutivo global: {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                'texto': "Error al generar resumen ejecutivo global. Se recomienda consultar los an√°lisis individuales.",
                'error': str(e)
            }

    def generate_ai_only_competition_report(self, idea, context, meta, extra_sources=""):
        print("üü¢ [CompetitorAnalysis] Iniciando generaci√≥n de informe AI-only para competencia...")
        idea_raw = idea.get('idea') if isinstance(idea, dict) and 'idea' in idea else str(idea)
        analysis_full = idea.get('analysis') if isinstance(idea, dict) and 'analysis' in idea else ""
        idea_brief, sector_keywords = self._get_brief_and_keywords(idea_raw, analysis_full)
        user_context = (context or "").strip()
        if user_context:
            contexto_usuario = self.SENER_CONTEXT + "\n\n" + user_context
        else:
            contexto_usuario = self.SENER_CONTEXT
        shared_inputs = {
            'idea_brief': idea_brief,
            'sector_keywords': sector_keywords,
            'score': meta.get('score'),
            'unidad_negocio': meta.get('unidad_negocio'),
            'idioma': meta.get('idioma', 'es'),
            'contexto_usuario': contexto_usuario,
            'analysis_full': analysis_full or "",
            'extra_sources': extra_sources or ""
        }
        section_map = [
            'COMPETITOR_MAPPING',
            'BENCHMARK_MATRIX',
            'TECH_IP_LANDSCAPE',
            'MARKET_ANALYSIS',
            'SWOT_POSITIONING',
            'REGULATORY_ESG_RISK'
        ]
        report_dict = {}
        from concurrent.futures import ThreadPoolExecutor, as_completed
        
        # üîß CRITICAL FIX: Process COMPETITOR_MAPPING first, then BENCHMARK_MATRIX with extracted competitors
        # ‚úÖ BENCHMARK_MATRIX EXCLUDED from first phase to avoid double processing
        section_map_first_phase = [
            'COMPETITOR_MAPPING',
            'TECH_IP_LANDSCAPE', 
            'MARKET_ANALYSIS',
            'SWOT_POSITIONING',
            'REGULATORY_ESG_RISK'
        ]
        print(f"üö®üö®üö® [DEBUG-FASE1] Secciones FASE 1 (SIN BENCHMARK): {section_map_first_phase}")
        
        # PHASE 1: Extract all sections EXCEPT BENCHMARK_MATRIX
        def extract_structured(section_id):
            try:
                # Prompt reforzado: SOLO datos estructurados, sin texto ni tablas Markdown.
                datos = self._extract_section_data_llm(section_id, shared_inputs, report_dict)
                
                # ‚úÖ VALIDACI√ìN MEJORADA: Verificar calidad de datos extra√≠dos
                if not datos:
                    print(f"‚ö†Ô∏è [CompetitorAnalysis] Datos vac√≠os para {section_id}, generando estructura b√°sica")
                    datos = self._generate_default_structure(section_id)
                elif isinstance(datos, dict):
                    # Verificar si contiene datos √∫tiles o solo mensajes de error
                    if 'aviso' in datos or 'error' in datos:
                        print(f"‚ö†Ô∏è [CompetitorAnalysis] Datos con aviso/error para {section_id}, intentando extracci√≥n b√°sica")
                        datos = self._generate_default_structure(section_id)
                    elif not any(datos.values()):
                        print(f"‚ö†Ô∏è [CompetitorAnalysis] Datos estructurados vac√≠os para {section_id}, generando estructura b√°sica")
                        datos = self._generate_default_structure(section_id)
                    else:
                        print(f"‚úÖ [CompetitorAnalysis] Datos estructurados v√°lidos extra√≠dos para {section_id}")
                else:
                    print(f"‚ö†Ô∏è [CompetitorAnalysis] Formato de datos inesperado para {section_id}, generando estructura b√°sica")
                    datos = self._generate_default_structure(section_id)
                    
            except Exception as e:
                print(f"‚ùå [CompetitorAnalysis] Error extrayendo datos para {section_id}: {e}")
                traceback.print_exc()
                # ‚úÖ GENERAR ESTRUCTURA B√ÅSICA EN LUGAR DE MENSAJE DE ERROR
                datos = self._generate_default_structure(section_id)
                
            return section_id, datos

        # 1.1 Extract first phase sections in parallel
        print("üîÑ [CompetitorAnalysis] FASE 1: Procesando secciones base...")
        with ThreadPoolExecutor(max_workers=min(5, self.max_workers)) as executor:
            futures = {executor.submit(extract_structured, section_id): section_id for section_id in section_map_first_phase}
            datos_dict = {}
            for future in as_completed(futures):
                section_id, datos = future.result()
                datos_dict[section_id] = datos
                # üö® CRITICAL: Add to report_dict immediately for BENCHMARK_MATRIX access
                report_dict[section_id] = {'datos': datos, 'texto': ''}

        # 1.2 Now extract BENCHMARK_MATRIX with COMPETITOR_MAPPING data available
        print("üîÑ [CompetitorAnalysis] FASE 2: Procesando BENCHMARK_MATRIX con competidores espec√≠ficos...")
        print(f"üö®üö®üö® [DEBUG-FASE2] report_dict keys antes de BENCHMARK: {list(report_dict.keys())}")
        
        try:
            print(f"üö®üö®üö® [DEBUG-FASE2] Llamando _extract_section_data_llm('BENCHMARK_MATRIX', shared_inputs, report_dict)")
            benchmark_datos = self._extract_section_data_llm('BENCHMARK_MATRIX', shared_inputs, report_dict)
            print(f"üö®üö®üö® [DEBUG-FASE2] Resultado: {type(benchmark_datos)}, keys: {list(benchmark_datos.keys()) if isinstance(benchmark_datos, dict) else 'No es dict'}")
            
            if not benchmark_datos:
                print(f"‚ö†Ô∏è [CompetitorAnalysis] Datos vac√≠os para BENCHMARK_MATRIX, generando estructura b√°sica")
                benchmark_datos = self._generate_default_structure('BENCHMARK_MATRIX')
            elif isinstance(benchmark_datos, dict):
                if 'aviso' in benchmark_datos or 'error' in benchmark_datos:
                    print(f"‚ö†Ô∏è [CompetitorAnalysis] Datos con aviso/error para BENCHMARK_MATRIX: {benchmark_datos}")
                    print(f"üö®üö®üö® [DEBUG-FASE2] FORZANDO USO DE DEFAULT STRUCTURE")
                    benchmark_datos = self._generate_default_structure('BENCHMARK_MATRIX')
                elif not any(benchmark_datos.values()):
                    print(f"‚ö†Ô∏è [CompetitorAnalysis] Datos estructurados vac√≠os para BENCHMARK_MATRIX, generando estructura b√°sica")
                    benchmark_datos = self._generate_default_structure('BENCHMARK_MATRIX')
                else:
                    print(f"‚úÖ [CompetitorAnalysis] Datos estructurados v√°lidos extra√≠dos para BENCHMARK_MATRIX")
                    print(f"üö®üö®üö® [DEBUG-FASE2] Datos v√°lidos: primeros 200 chars = {str(benchmark_datos)[:200]}")
            else:
                print(f"‚ö†Ô∏è [CompetitorAnalysis] Formato de datos inesperado para BENCHMARK_MATRIX: {type(benchmark_datos)}")
                benchmark_datos = self._generate_default_structure('BENCHMARK_MATRIX')
        except Exception as e:
            print(f"‚ùå [CompetitorAnalysis] Error extrayendo datos para BENCHMARK_MATRIX: {e}")
            traceback.print_exc()
            benchmark_datos = self._generate_default_structure('BENCHMARK_MATRIX')
            
        datos_dict['BENCHMARK_MATRIX'] = benchmark_datos
        report_dict['BENCHMARK_MATRIX'] = {'datos': benchmark_datos, 'texto': ''}

        # 2. Redactar texto explicativo profesional en paralelo (sin recomendaciones ni conclusiones)
        print("üîÑ [CompetitorAnalysis] FASE 3: Redactando textos explicativos...")
        section_map_complete = section_map_first_phase + ['BENCHMARK_MATRIX']
        
        def redactar_explicativo(section_id):
            datos = datos_dict[section_id]
            # Prompt reforzado: SOLO an√°lisis profesional, sin tablas, sin referencias en bruto, sin t√≠tulos internos.
            custom_instruction = (
                "Redacta un texto explicativo profesional, extenso y consultor para la secci√≥n, usando SOLO los datos estructurados extra√≠dos a continuaci√≥n. "
                "NO incluyas recomendaciones ni conclusiones finales. NO repitas puntos ni mezcles informaci√≥n. NO inventes nada. "
                "NO incluyas tablas, t√≠tulos internos, ni referencias en bruto. NO incluyas ning√∫n bloque de tabla ni referencias en el texto. "
                "El texto debe ser lo m√°s extenso y profesional posible, con an√°lisis profundo, contexto sectorial, implicaciones estrat√©gicas, riesgos y oportunidades, pero SOLO sobre los datos extra√≠dos."
            )
            try:
                texto = self._redact_section_llm(section_id, shared_inputs, datos, report_dict, custom_instruction=custom_instruction)
                if not texto or not texto.strip():
                    texto = "[No se pudo generar an√°lisis profesional para esta secci√≥n. Consulte fuentes primarias.]"
                print(f"‚úÖ [CompetitorAnalysis] Texto explicativo redactado para {section_id}")
            except Exception as e:
                print(f"‚ùå [CompetitorAnalysis] Error redactando texto para {section_id}: {e}")
                traceback.print_exc()
                texto = "[Error al redactar secci√≥n]"
            return section_id, texto
            
        with ThreadPoolExecutor(max_workers=min(6, self.max_workers)) as executor:
            futures = {executor.submit(redactar_explicativo, section_id): section_id for section_id in section_map_complete}
            textos_dict = {}
            for future in as_completed(futures):
                section_id, texto = future.result()
                textos_dict[section_id] = texto

        # 3. Montar el informe final
        for section_id in section_map_complete:
            report_dict[section_id] = {
                'datos': datos_dict.get(section_id, {}),
                'texto': textos_dict.get(section_id, "")
            }

        # --- EXEC_SUMMARY comentado - ser√° generado globalmente ---
        # NOTA: El resumen ejecutivo se genera ahora a nivel global para todas las ideas
        print("‚ÑπÔ∏è [CompetitorAnalysis] Resumen ejecutivo ser√° generado globalmente.")
        report_dict['metadatos'] = {
            "origen": "AI-only (scraping desactivado)",
            "fecha_generacion": datetime.now().isoformat(),
            "modelo": self.deployment_name if hasattr(self, 'deployment_name') else "openai",
            "secciones_generadas": list(report_dict.keys())
        }
        report_dict = fill_empty_sections(report_dict)
        # --- MEJORA: asegurar que todas las secciones sean homog√©neas para PDF ---
        report_dict = _coerce_sections_for_pdf(report_dict)
        print("üéâ [CompetitorAnalysis] Informe AI-only generado correctamente.")
        return report_dict

    def _extract_text_from_pdf(self, url_or_path):
        """
        Extrae texto de un PDF desde una URL o path local usando pdf_processor_module.extract_text_from_pdf.
        """
        import tempfile
        import requests
        from pdf_processor_module import extract_text_from_pdf
        try:
            if url_or_path.startswith("http"):
                # Descargar PDF a un archivo temporal
                resp = requests.get(url_or_path, timeout=15)
                resp.raise_for_status()
                with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
                    tmp.write(resp.content)
                    tmp_path = tmp.name
                text = extract_text_from_pdf(tmp_path)
                return text or ""
            else:
                # Path local
                return extract_text_from_pdf(url_or_path) or ""
        except Exception as e:
            print(f"‚ùå Error extrayendo texto de PDF: {e}")
            return ""

    def generate_llm_draft(self, idea: Dict[str, Any], contexto_usuario: str = "") -> Dict[str, Any]:
        """
        Llama al LLM para generar el informe completo, secci√≥n por secci√≥n, con posibles scraping_requests.
        """
        meta = {"fecha": datetime.now().isoformat()}
        # Aqu√≠ puedes usar la l√≥gica de generate_ai_only_competition_report, pero asegurando que cada secci√≥n puede devolver 'scraping_requests'.
        return self.generate_ai_only_competition_report(idea, contexto_usuario, meta)

    def analyze_idea(self, idea: Dict[str, Any], contexto_usuario: str = "") -> Dict[str, Any]:
        print("üü¢ [CompetitorAnalysis] Iniciando an√°lisis de idea...")
        import json
        from urllib.parse import urlparse
        def is_valid_url(url):
            try:
                parsed = urlparse(url)
                return parsed.scheme in ["http", "https"] and bool(parsed.netloc)
            except Exception:
                return False
        # --- Paso 1: Generar borrador LLM completo (con textos profesionales) ---
        borrador = self.generate_llm_draft(idea, contexto_usuario)
        # Log borrador para depuraci√≥n
        try:
            with open("output/last_llm_draft.json", "w", encoding="utf-8") as f:
                json.dump(borrador, f, indent=2, ensure_ascii=False)
            print("üíæ [CompetitorAnalysis] Borrador LLM guardado en output/last_llm_draft.json")
        except Exception as e:
            print(f"[WARN] No se pudo guardar borrador LLM: {e}")
        scraping_requests = []
        # Paso 2: buscar scraping_requests en el borrador o en sus secciones
        if isinstance(borrador, dict):
            if 'scraping_requests' in borrador and isinstance(borrador['scraping_requests'], list):
                scraping_requests = borrador['scraping_requests']
            else:
                for v in borrador.values():
                    if isinstance(v, dict) and 'scraping_requests' in v and isinstance(v['scraping_requests'], list):
                        scraping_requests.extend(v['scraping_requests'])
        # --- NUEVO: detectar URLs en los datos extra√≠dos y a√±adir scraping_requests autom√°ticamente ---
        def find_urls(obj):
            urls = []
            if isinstance(obj, dict):
                for k, v in obj.items():
                    if k.lower() in ("url", "fuente", "scrape_url") and isinstance(v, str) and is_valid_url(v):
                        urls.append(v)
                    else:
                        urls.extend(find_urls(v))
            elif isinstance(obj, list):
                for item in obj:
                    urls.extend(find_urls(item))
            return urls
        extra_urls = find_urls(borrador)
        for url in extra_urls:
            scraping_requests.append({'url': url, 'type': 'auto'})
        # Validar URLs antes de scrappear
        scraping_requests = [req for req in scraping_requests if isinstance(req, dict) and is_valid_url(req.get('url',''))]
        print(f"üîç [CompetitorAnalysis] Scraping requests detectados: {len(scraping_requests)}")
        # Log scraping_requests
        try:
            with open("output/last_scraping_requests.json", "w", encoding="utf-8") as f:
                json.dump(scraping_requests, f, indent=2, ensure_ascii=False)
            print("üíæ [CompetitorAnalysis] Scraping requests guardados en output/last_scraping_requests.json")
        except Exception as e:
            print(f"[WARN] No se pudo guardar scraping_requests: {e}")
        if scraping_requests:
            try:
                from targeted_scraper import scrape_targets
                from integrator import merge_llm_and_data
                print("üü† [CompetitorAnalysis] Ejecutando scraping puntual...")
                datos_scrapeados = scrape_targets(scraping_requests)
                print("‚úÖ [CompetitorAnalysis] Scraping completado.")
                # Log datos_scrapeados
                try:
                    with open("output/last_scraped_data.json", "w", encoding="utf-8") as f:
                        json.dump(datos_scrapeados, f, indent=2, ensure_ascii=False)
                    print("üíæ [CompetitorAnalysis] Datos scrapeados guardados en output/last_scraped_data.json")
                except Exception as e:
                    print(f"[WARN] No se pudo guardar datos_scrapeados: {e}")
                try:
                    informe_final = merge_llm_and_data(borrador, datos_scrapeados)
                    print("‚úÖ [CompetitorAnalysis] Integraci√≥n de datos scrapeados completada.")
                    # Log informe_final
                    try:
                        with open("output/last_integrated_report.json", "w", encoding="utf-8") as f:
                            json.dump(informe_final, f, indent=2, ensure_ascii=False)
                        print("üíæ [CompetitorAnalysis] Informe final guardado en output/last_integrated_report.json")
                    except Exception as e:
                        print(f"[WARN] No se pudo guardar informe_final: {e}")
                    return informe_final
                except Exception as e:
                    print(f"[WARN] Integraci√≥n scraping+LLM fall√≥: {e}")
                    traceback.print_exc()
                    print("üü¢ [CompetitorAnalysis] Scraping fallido, devolviendo borrador LLM-only (con textos profesionales).")
                    return borrador
            except Exception as e:
                print(f"[WARN] Scraping fall√≥: {e}")
                traceback.print_exc()
                print("üü¢ [CompetitorAnalysis] Scraping fallido, devolviendo borrador LLM-only (con textos profesionales).")
                return borrador
        else:
            print("üü¢ [CompetitorAnalysis] No se requieren scraping requests. Devolviendo borrador LLM-only (con textos profesionales).")
            return borrador

    def _generate_default_structure(self, section_id):
        """
        Genera estructuras de datos b√°sicas pero v√°lidas cuando el LLM falla en la extracci√≥n.
        ‚úÖ NUEVA FUNCI√ìN: Alternativa a mensajes de error gen√©ricos
        """
        import json
        
        defaults = {
            'COMPETITOR_MAPPING': {
                "competidores_directos": [
                    {
                        "nombre": "An√°lisis espec√≠fico pendiente",
                        "pais": "Global",
                        "sector": "Ingenier√≠a y construcci√≥n",
                        "tamano": "Mediana",
                        "descripcion": "Requiere investigaci√≥n espec√≠fica del sector",
                        "website": "Pendiente de identificaci√≥n"
                    }
                ],
                "competidores_indirectos": [
                    {
                        "nombre": "Evaluaci√≥n de mercado pendiente",
                        "pais": "Global",
                        "sector": "Tecnolog√≠a e infraestructura",
                        "tamano": "Grande",
                        "descripcion": "Requiere an√°lisis detallado del ecosistema competitivo",
                        "website": "En proceso de identificaci√≥n"
                    }
                ],
                "emergentes": [
                    {
                        "nombre": "Startups del sector pendientes de identificar",
                        "pais": "M√∫ltiples regiones",
                        "sector": "Innovaci√≥n tecnol√≥gica",
                        "tamano": "Peque√±a",
                        "descripcion": "Monitoreo de empresas emergentes en desarrollo",
                        "website": "B√∫squeda en bases de datos especializadas"
                    }
                ]
            },
            'BENCHMARK_MATRIX': {
                "tabla": [
                    {
                        "nombre": "An√°lisis comparativo en desarrollo",
                        "pais": "Global",
                        "sector": "Ingenier√≠a",
                        "tamano": "Mediana",
                        "enfoque_estrategico": "Requiere estudio espec√≠fico de estrategias competitivas",
                        "modelo_negocio": "Evaluaci√≥n de modelos en proceso",
                        "diferenciador_clave": "Identificaci√≥n de ventajas competitivas pendiente"
                    }
                ],
                "analisis_cualitativo": {
                    "gaps_identificados": [
                        "An√°lisis de brechas competitivas en desarrollo",
                        "Identificaci√≥n de oportunidades de diferenciaci√≥n pendiente"
                    ],
                    "oportunidades_sener": [
                        "Evaluaci√≥n de posicionamiento estrat√©gico en proceso",
                        "An√°lisis de capacidades diferenciadas de Sener en desarrollo"
                    ]
                }
            },
            'TECH_IP_LANDSCAPE': {
                "patentes_destacadas": [
                    {
                        "titulo": "Tecnolog√≠as del sector espec√≠fico",
                        "numero_patente": "Disponible en bases de datos especializadas",
                        "titular": "Empresas l√≠deres del sector",
                        "a√±o": "2020-2024",
                        "pais": "Global",
                        "descripcion": "An√°lisis de patentes relevantes para el √°rea tecnol√≥gica espec√≠fica de la idea",
                        "relevancia_competitiva": "Evaluaci√≥n de impacto tecnol√≥gico en desarrollo",
                        "url": "Disponible en Google Patents y bases de datos especializadas"
                    }
                ],
                "publicaciones_clave": [
                    {
                        "titulo": "Investigaci√≥n acad√©mica del sector",
                        "autores": "Investigadores especializados en el √°rea",
                        "revista": "Revistas cient√≠ficas del sector espec√≠fico",
                        "a√±o": "2020-2024",
                        "tipo": "Art√≠culo de investigaci√≥n",
                        "resumen": "Estado del arte cient√≠fico relacionado con la tecnolog√≠a de la idea",
                        "relevancia_tecnologica": "Contribuci√≥n al avance del conocimiento sectorial",
                        "url": "Disponible en bases de datos acad√©micas especializadas"
                    }
                ],
                "gaps_tecnologicos": [
                    {
                        "area_tecnologica": "√Årea espec√≠fica de la idea analizada",
                        "descripcion_gap": "Limitaciones tecnol√≥gicas identificadas en el mercado actual",
                        "impacto_competitivo": "Efecto en la competitividad del sector",
                        "oportunidad_sener": "Potencial para Sener de abordar estas limitaciones tecnol√≥gicas"
                    }
                ],
                "tendencias_emergentes": [
                    {
                        "tecnologia": "Tecnolog√≠as emergentes del sector espec√≠fico",
                        "estado_madurez": "Desarrollo",
                        "potencial_disruptivo": "Medio",
                        "plazo_adopcion": "3-5 a√±os"
                    }
                ]
            },
            'MARKET_ANALYSIS': {
                "TAM_2025": 0,  # Se requiere investigaci√≥n espec√≠fica
                "CAGR_2025_2030": 0,  # Pendiente de an√°lisis sectorial
                "segmentos": [
                    "Segmentaci√≥n de mercado pendiente de an√°lisis espec√≠fico"
                ],
                "geografias": [
                    "An√°lisis geogr√°fico en desarrollo"
                ],
                "drivers": [
                    "Factores de crecimiento del sector en identificaci√≥n"
                ],
                "restrictores": [
                    "Barreras del mercado en evaluaci√≥n"
                ],
                "analisis_cualitativo": {
                    "gaps_identificados": [
                        "Vac√≠os de mercado en proceso de identificaci√≥n espec√≠fica",
                        "An√°lisis de necesidades no cubiertas en desarrollo"
                    ],
                    "oportunidades_sener": [
                        "Evaluaci√≥n de oportunidades estrat√©gicas para Sener en proceso",
                        "Identificaci√≥n de ventajas competitivas aplicables en desarrollo"
                    ]
                }
            },
            'SWOT_POSITIONING': {
                "swot": {
                    "fortalezas": [
                        "Experiencia de Sener en ingenier√≠a aplicable al sector espec√≠fico",
                        "Capacidades t√©cnicas y tecnol√≥gicas de la organizaci√≥n",
                        "Trayectoria en proyectos de alta complejidad t√©cnica"
                    ],
                    "debilidades": [
                        "Evaluaci√≥n de limitaciones espec√≠ficas para esta idea en proceso",
                        "An√°lisis de gaps de capacidades sectoriales en desarrollo",
                        "Identificaci√≥n de √°reas de mejora competitiva pendiente"
                    ],
                    "oportunidades": [
                        "Tendencias del mercado favorables al desarrollo de la idea",
                        "Sinergias con capacidades existentes de Sener en el sector",
                        "Potencial de crecimiento del mercado espec√≠fico"
                    ],
                    "amenazas": [
                        "An√°lisis de riesgos competitivos en evaluaci√≥n",
                        "Identificaci√≥n de barreras regulatorias en proceso",
                        "Evaluaci√≥n de factores de riesgo del sector en desarrollo"
                    ]
                },
                "mapa_posicionamiento": {
                    "eje_x": "Especializaci√≥n t√©cnica vs Generalizaci√≥n",
                    "eje_y": "Tama√±o de mercado vs Nicho especializado",
                    "comentario": "Posicionamiento estrat√©gico de la idea en an√°lisis"
                }
            },
            'REGULATORY_ESG_RISK': {
                "normativas_clave": [
                    "An√°lisis normativo del sector en desarrollo"
                ],
                "certificaciones": [
                    "Requisitos de certificaci√≥n en evaluaci√≥n"
                ],
                "riesgos": [
                    "Identificaci√≥n de riesgos regulatorios en proceso"
                ],
                "oportunidades_ESG": [
                    "Evaluaci√≥n de oportunidades de sostenibilidad en desarrollo"
                ]
            },
            'STRATEGIC_ROADMAP': {
                "acciones_90_dias": [
                    "Planificaci√≥n estrat√©gica inicial en desarrollo"
                ],
                "acciones_12_meses": [
                    "Roadmap de mediano plazo en elaboraci√≥n"
                ],
                "acciones_36_meses": [
                    "Estrategia de largo plazo en definici√≥n"
                ],
                "KPIs_clave": [
                    "Definici√≥n de m√©tricas de √©xito en proceso"
                ]
            },
            'APPENDIX': {
                "glosario": {
                    "An√°lisis competitivo": "Evaluaci√≥n sistem√°tica del entorno competitivo",
                    "Vigilancia tecnol√≥gica": "Monitoreo de avances y tendencias tecnol√≥gicas"
                },
                "metodologia": "An√°lisis basado en informaci√≥n sectorial y capacidades de Sener",
                "limitaciones": "An√°lisis preliminar que requiere investigaci√≥n espec√≠fica adicional"
            }
        }
        
        default_structure = defaults.get(section_id, {})
        print(f"üîÑ [CompetitorAnalysis] Generada estructura por defecto para {section_id}")
        return default_structure

    def _extract_patent_info(self, patent_result):
        """
        Extrae informaci√≥n estructurada de un resultado de patente real.
        """
        try:
            patent_info = {}
            
            # Extraer campos b√°sicos
            patent_info['titulo'] = patent_result.get('title', '').strip()
            patent_info['numero_patente'] = patent_result.get('publication_number', '').strip()
            patent_info['titular'] = patent_result.get('assignee', '').strip()
            patent_info['a√±o'] = patent_result.get('publication_date', '').split('-')[0] if patent_result.get('publication_date') else ''
            patent_info['pais'] = patent_result.get('publication_number', '')[:2] if patent_result.get('publication_number') else ''
            patent_info['descripcion'] = patent_result.get('snippet', '').strip()[:200]
            
            # Construir URL de Google Patents
            patent_id = patent_result.get('patent_id', '')
            if patent_id:
                patent_info['url'] = f"https://patents.google.com/{patent_id}"
            
            # Validar que tenemos informaci√≥n m√≠nima
            if patent_info['titulo'] and patent_info['numero_patente']:
                return patent_info
            else:
                return None
                
        except Exception as e:
            import logging
            logging.warning(f"[Patents] ‚ö†Ô∏è Error extrayendo info de patente: {e}")
            return None

    def _redact_section_llm(self, section_id, shared_inputs, datos, report_dict=None, custom_instruction=""):
        """
        Usa el LLM para redactar texto explicativo profesional sobre una secci√≥n espec√≠fica.
        ‚úÖ MEJORADO: Instrucciones espec√≠ficas por secci√≥n
        """
        idea_text = shared_inputs.get('idea_text', '').strip()
        analisis_full = shared_inputs.get('analysis_full', '').strip()
        context_usuario = shared_inputs.get('context_usuario', '').strip()
        
        # ‚úÖ INSTRUCCIONES ESPEC√çFICAS POR SECCI√ìN
        if section_id == "COMPETITOR_MAPPING":
            prompt_instruction = (
                "Redacta un an√°lisis DESCRIPTIVO del ecosistema competitivo (m√°ximo 350 palabras) para la idea analizada. "
                
                "ENFOQUE DESCRIPTIVO (NO comparativo): "
                "- DESCRIBE qu√© hace cada competidor y su rol en el ecosistema "
                "- EXPLICA por qu√© cada empresa es relevante para el sector "
                "- IDENTIFICA las diferentes categor√≠as de competencia (directos, indirectos, emergentes) "
                "- ANALIZA la estructura general del mercado competitivo "
                "- DESCRIBE tendencias y din√°micas del sector "
                
                "CONTENIDO OBLIGATORIO: "
                "- Menciona espec√≠ficamente CADA empresa de los datos estructurados "
                "- Explica el rol y actividad principal de cada competidor "
                "- Describe la intensidad competitiva del segmento "
                "- Identifica patrones en el ecosistema competitivo "
                
                "FORMATO: P√°rrafos descriptivos fluidos, sin numeraciones ni comparaciones directas. "
                "ESTILO: Consultor que mapea y describe el panorama competitivo. "
                
                "PROHIBIDO: "
                "- NO hagas comparaciones directas entre empresas (eso va en Benchmarking) "
                "- NO uses '1) COMPETIDORES DIRECTOS', '2) INDIRECTOS' etc. "
                "- NO pongas subt√≠tulos internos "
                "- NO menciones gaps de mercado ni oportunidades (van en Market Analysis) "
                
                "FORMATO: An√°lisis fluido y natural basado SOLO en los competidores identificados por el LLM. "
                "Menciona de forma natural todos los competidores de los datos estructurados sin ejemplos predefinidos."
            )
        elif section_id == "BENCHMARK_MATRIX":
            prompt_instruction = (
                "Redacta un an√°lisis COMPARATIVO de benchmarking estrat√©gico (m√°ximo 350 palabras) entre los competidores clave. "
                
                "ENFOQUE COMPARATIVO (NO descriptivo): "
                "- COMPARA modelos de negocio entre competidores "
                "- CONTRASTA diferenciadores competitivos √∫nicos "
                "- ANALIZA patrones de especializaci√≥n vs generalizaci√≥n "
                "- EVAL√öA ventajas competitivas relativas "
                "- IDENTIFICA factores cr√≠ticos de √©xito comunes y √∫nicos "
                
                "CONTENIDO OBLIGATORIO: "
                "- Comparaciones directas entre enfoques estrat√©gicos "
                "- An√°lisis de similitudes y diferencias en modelos de negocio "
                "- Evaluaci√≥n de ventajas competitivas relativas "
                "- Identificaci√≥n de patrones de √©xito en el sector "
                
                "FORMATO: P√°rrafos comparativos fluidos, an√°lisis 'versus' y contrastes. "
                "ESTILO: Consultor que compara y eval√∫a estrategias competitivas. "
                
                "PROHIBIDO TOTALMENTE: "
                "- Descripciones simples de qu√© hace cada empresa (eso va en Mapa) "
                "- Gaps de mercado u oportunidades para Sener (van en Market Analysis) "
                "- Cifras espec√≠ficas, n√∫meros de empleados, ingresos inventados "
                
                "ENFOQUE: An√°lisis puramente comparativo y estrat√©gico de lo que hacen los competidores. "
                "FORMATO: P√°rrafos fluidos sin listas numeradas ni formato Markdown. "
                "RESPONDE SIEMPRE EN ESPA√ëOL."
            )
        else:
            # Prompt gen√©rico para otras secciones
            prompt_instruction = custom_instruction or (
                "Redacta un texto explicativo profesional, extenso y consultor para la secci√≥n, usando SOLO los datos estructurados extra√≠dos a continuaci√≥n. "
                "NO incluyas recomendaciones ni conclusiones finales. NO repitas puntos ni mezcles informaci√≥n. NO inventes nada. "
                "NO incluyas tablas, t√≠tulos internos, ni referencias en bruto. "
                "El texto debe ser lo m√°s extenso y profesional posible, con an√°lisis profundo, contexto sectorial, implicaciones estrat√©gicas, riesgos y oportunidades, pero SOLO sobre los datos extra√≠dos."
            )
        
        prompt = f"""
        INSTRUCCI√ìN: {prompt_instruction}

        CONTEXTO DE LA IDEA:
        {idea_text[:800]}

        DATOS EXTRA√çDOS PARA LA SECCI√ìN:
        {json.dumps(datos, indent=2, ensure_ascii=False) if isinstance(datos, (dict, list)) else str(datos)[:1000]}

        CONTEXTO ADICIONAL DEL USUARIO:
        {context_usuario[:400] if context_usuario else "No hay contexto adicional."}

        Redacta el an√°lisis profesional solicitado:
        """
        
        try:
            response = self.openai_client.chat.completions.create(
            model=self.deployment_name,
            messages=[
                    {"role": "system", "content": f"Eres un analista estrat√©gico senior especializado en {section_id}. Redactas an√°lisis profesionales concisos y accionables para empresas de ingenier√≠a como Sener."},
                {"role": "user", "content": prompt}
            ],
                temperature=0.6,
                max_tokens=800 if section_id == "COMPETITOR_MAPPING" else 1200,
                timeout=45
                )
            
            texto = response.choices[0].message.content.strip()
            if not texto:
                return f"[No se pudo generar an√°lisis para {section_id}]"
            return texto
            
        except Exception as e:
            print(f"‚ùå Error redactando secci√≥n {section_id}: {e}")
            return f"[Error al generar an√°lisis para {section_id}]"

    def _get_brief_and_keywords(self, idea_raw, analysis_full=None):
        """
        Llama al LLM para obtener un brief y 5-8 palabras clave sectoriales, usando tambi√©n el an√°lisis completo si existe.
        """
        prompt = (
            "Devuelve SOLO un objeto JSON con dos campos: 'brief' (resumen de la idea en 2-3 frases) y 'keywords' (lista de 5-8 palabras clave sectoriales, en min√∫sculas, separadas por coma). Nada fuera del JSON.\n\nIDEA:\n" + idea_raw[:800]
        )
        if analysis_full:
            prompt += f"\n\nANALISIS_COMPLETO:\n{analysis_full[:1200]}"
        try:
            resp = self.openai_client.chat.completions.create(
                model=self.deployment_name,
                messages=[
                    {"role": "system", "content": "Eres un analista experto en s√≠ntesis de ideas y extracci√≥n de palabras clave."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=300,
                response_format={"type": "json_object"}
            )
            data = json.loads(resp.choices[0].message.content)
            brief = data.get('brief', '')
            keywords = data.get('keywords', '')
            if isinstance(keywords, str):
                keywords = [k.strip() for k in keywords.split(',') if k.strip()]
            return brief, keywords
        except Exception as e:
            print(f"‚ö†Ô∏è Error extrayendo brief/keywords: {e}")
            return idea_raw[:200], []

    # üÜï NUEVA FUNCI√ìN: PRE-FILTRO INTELIGENTE DE FUENTES POR SECCI√ìN
    def get_relevant_sources_for_section(self, section_id, extra_sources, idea_brief):
        """
        üß† PRE-FILTRO INTELIGENTE: El LLM eval√∫a qu√© fuentes son relevantes para cada secci√≥n espec√≠fica
        
        Args:
            section_id: ID de la secci√≥n (COMPETITOR_MAPPING, TECH_IP_LANDSCAPE, etc.)
            extra_sources: String con fuentes especificadas por el usuario (ej: "Crunchbase, LinkedIn, Patents")
            idea_brief: Resumen de la idea para contexto
            
        Returns:
            String con fuentes relevantes separadas por comas, o string vac√≠o si ninguna es relevante
        """
        print(f"üîçüîçüîç [PRE-FILTRO] ===== INICIANDO PRE-FILTRO PARA {section_id} =====")
        print(f"üîçüîçüîç [PRE-FILTRO] extra_sources recibido: '{extra_sources}'")
        print(f"üîçüîçüîç [PRE-FILTRO] idea_brief: '{idea_brief[:100]}...'")
        
        # üö´ EXCLUIR BENCHMARK_MATRIX - se nutre del COMPETITOR_MAPPING
        if section_id == "BENCHMARK_MATRIX":
            print(f"üîçüîçüîç [PRE-FILTRO] ‚ùå BENCHMARK_MATRIX EXCLUIDO - retornando vac√≠o")
            return ""
        
        if not extra_sources or not extra_sources.strip():
            print(f"üîçüîçüîç [PRE-FILTRO] ‚ùå NO HAY FUENTES - retornando vac√≠o")
            return ""
        
        print(f"üîçüîçüîç [PRE-FILTRO] ‚úÖ FUENTES DETECTADAS - continuando con pre-filtro")
        
        try:
            # Prompt espec√≠fico para el pre-filtro
            prompt = f"""
TAREA: Evaluar qu√© fuentes son relevantes para la secci√≥n {section_id}.

CONTEXTO DE LA IDEA: {idea_brief}

FUENTES DISPONIBLES: {extra_sources}

SECCI√ìN A ANALIZAR: {section_id}

INSTRUCCIONES:
1. Eval√∫a SOLO si cada fuente aporta valor espec√≠fico para la secci√≥n {section_id}
2. Si una fuente NO es relevante para esta secci√≥n espec√≠fica, NO la incluyas
3. Responde √öNICAMENTE con las fuentes relevantes separadas por comas
4. Si ninguna fuente es relevante, responde con "NINGUNA"

EJEMPLO DE RESPUESTA: "Crunchbase, LinkedIn" o "NINGUNA"

RESPUESTA:"""

            print(f"üîçüîçüîç [PRE-FILTRO] üìù PROMPT GENERADO:")
            print(f"üîçüîçüîç [PRE-FILTRO] {prompt}")
            print(f"üîçüîçüîç [PRE-FILTRO] üöÄ LLAMANDO AL LLM...")
            
            response = self.openai_client.chat.completions.create(
                model=self.deployment_name,
                messages=[
                    {"role": "system", "content": "Eres un experto en an√°lisis competitivo. Eval√∫a √∫nicamente la relevancia de fuentes para secciones espec√≠ficas."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=100
            )
            
            if not response or not response.choices or not response.choices[0].message:
                print(f"üîçüîçüîç [PRE-FILTRO] ‚ùå RESPUESTA LLM VAC√çA")
                return ""
            
            raw_response = response.choices[0].message.content.strip()
            print(f"üîçüîçüîç [PRE-FILTRO] üì• RESPUESTA RAW LLM: '{raw_response}'")
            
            # üîß SOLUCI√ìN COMILLAS: Limpiar comillas de la respuesta del LLM
            # Quitar comillas dobles que rodean toda la respuesta
            if raw_response.startswith('"') and raw_response.endswith('"'):
                raw_response = raw_response[1:-1]
                print(f"üîçüîçüîç [PRE-FILTRO] üîß COMILLAS ELIMINADAS: '{raw_response}'")
            
            if raw_response.upper() == "NINGUNA" or not raw_response:
                print(f"üîçüîçüîç [PRE-FILTRO] ‚ùå LLM DICE 'NINGUNA' - retornando vac√≠o")
                return ""
            
            # Procesar la respuesta
            relevant_sources = [s.strip() for s in raw_response.split(',') if s.strip()]
            print(f"üîçüîçüîç [PRE-FILTRO] üîÑ FUENTES PROCESADAS: {relevant_sources}")
            
            # Validar que las fuentes est√°n en la lista original
            if relevant_sources:
                extra_sources_list = [s.strip() for s in extra_sources.split(',')]
                extra_sources_lower = [s.lower() for s in extra_sources_list]
                
                print(f"üîçüîçüîç [PRE-FILTRO] üîÑ FUENTES ORIGINALES: {extra_sources_list}")
                print(f"üîçüîçüîç [PRE-FILTRO] üîÑ FUENTES ORIGINALES LOWER: {extra_sources_lower}")
                
                filtered_sources = []
                for source in relevant_sources:
                    # Buscar coincidencias case-insensitive
                    for i, orig_lower in enumerate(extra_sources_lower):
                        if source.lower() == orig_lower:
                            filtered_sources.append(extra_sources_list[i])  # Usar original con may√∫sculas
                            print(f"üîçüîçüîç [PRE-FILTRO] ‚úÖ FUENTE VALIDADA: '{source}' -> '{extra_sources_list[i]}'")
                            break
                    else:
                        print(f"üîçüîçüîç [PRE-FILTRO] ‚ö†Ô∏è FUENTE NO ENCONTRADA EN ORIGINALES: '{source}'")
                
                result = ", ".join(filtered_sources)
                print(f"üîçüîçüîç [PRE-FILTRO] üéâ RESULTADO FINAL: '{result}'")
                return result
            
            print(f"üîçüîçüîç [PRE-FILTRO] ‚ùå NO HAY FUENTES RELEVANTES DESPU√âS DE PROCESAR")
            return ""
            
        except Exception as e:
            print(f"üîçüîçüîç [PRE-FILTRO] ‚ùå ERROR: {str(e)}")
            import traceback
            traceback.print_exc()
            return ""

def fill_empty_sections(report_data):
    """
    Rellena cualquier secci√≥n vac√≠a o con 'No disponible' con textos profesionales y extensos por defecto.
    """
    default_texts = {
        'resumen_ejecutivo': "No se encontraron datos espec√≠ficos, pero en el sector suelen observarse las siguientes tendencias y recomendaciones. Es recomendable realizar un an√°lisis de mercado m√°s profundo y consultar fuentes primarias para obtener informaci√≥n detallada. La digitalizaci√≥n, la sostenibilidad y la eficiencia suelen ser factores clave en la industria. Se recomienda identificar oportunidades de innovaci√≥n y alianzas estrat√©gicas, as√≠ como desarrollar un plan de acci√≥n basado en las mejores pr√°cticas del sector.",
        'analisis_mercado': "No se encontraron datos espec√≠ficos de mercado. Sin embargo, en el sector es habitual observar tendencias como la digitalizaci√≥n, la sostenibilidad y la b√∫squeda de eficiencia. Se recomienda analizar informes de mercado sectoriales y consultar fuentes especializadas para obtener datos cuantitativos y cualitativos relevantes.",
        'benchmarking': "No se encontraron datos de benchmarking espec√≠ficos. Se recomienda analizar a los principales actores del sector y comparar tecnolog√≠as, modelos de negocio y precios. El benchmarking permite identificar oportunidades de mejora y diferenciarse de la competencia.",
        'vigilancia_tecnologica': "No se encontraron datos de vigilancia tecnol√≥gica espec√≠ficos. Es recomendable consultar bases de datos de patentes y publicaciones cient√≠ficas para identificar innovaciones relevantes. La vigilancia tecnol√≥gica es clave para anticipar tendencias y detectar oportunidades de innovaci√≥n.",
        'dafo': "No se pudo realizar un an√°lisis DAFO detallado. Sin embargo, en el sector suelen destacarse fortalezas como la innovaci√≥n, oportunidades en mercados emergentes, debilidades relacionadas con la falta de datos y amenazas como la competencia global y los cambios regulatorios.",
        'recomendaciones': [
            "Se recomienda realizar un an√°lisis de mercado m√°s profundo y consultar fuentes primarias.",
            "Identificar oportunidades de innovaci√≥n y alianzas estrat√©gicas.",
            "Desarrollar un plan de acci√≥n basado en las mejores pr√°cticas del sector.",
            "Implementar un sistema de vigilancia tecnol√≥gica continua para anticipar tendencias.",
            "Revisar peri√≥dicamente la estrategia competitiva y adaptarse a los cambios del mercado."
        ],
        'conclusion_final': "No se pudo extraer una conclusi√≥n final detallada. Se sugiere revisar peri√≥dicamente el entorno competitivo y ajustar la estrategia en funci√≥n de los cambios del mercado. La adaptabilidad y la innovaci√≥n continua son factores clave para el √©xito a largo plazo."
    }
    for key, default in default_texts.items():
        if key not in report_data or not report_data[key] or (isinstance(report_data[key], str) and report_data[key].strip().lower() in ["no disponible.", "no disponible", ""]):
            report_data[key] = default
        elif isinstance(report_data[key], list) and not report_data[key]:
            report_data[key] = default if isinstance(default, list) else [default]
    return report_data

# --- A√±adir funci√≥n de homogeneizaci√≥n de secciones para PDF ---
def _coerce_sections_for_pdf(secciones: dict) -> dict:
    """
    Convierte listas o strings en dicts {'texto': ‚Ä¶} para que el generador PDF no falle con .get('texto').
    Si el valor es un dict y ya contiene 'texto', lo deja tal cual.
    Si es una lista de dicts grande, la convierte en tabla (cabeceras + filas).
    Si la lista es muy grande (>10), la trunca y a√±ade aviso.
    """
    import json
    coerced = {}
    for k, v in secciones.items():
        if k == 'metadatos':
            continue
        if isinstance(v, dict):
            if 'texto' in v:
                coerced[k] = v
            else:
                coerced[k] = v
        elif isinstance(v, list):
            # Detectar lista de dicts homog√©nea
            if v and all(isinstance(el, dict) for el in v):
                # Construir tabla: cabeceras = claves comunes
                headers = list({key for d in v for key in d.keys()})
                rows = []
                N = 10
                for el in v[:N]:
                    row = [str(el.get(h, '')) for h in headers]
                    rows.append(row)
                table_str = "\t".join(headers) + "\n" + "\n".join(["\t".join(row) for row in rows])
                if len(v) > N:
                    table_str += f"\n... (mostrando solo los primeros {N} elementos de {len(v)})"
                coerced[k] = {"texto": table_str}
            else:
                joined = "\n".join(
                    json.dumps(el, ensure_ascii=False, indent=2) if isinstance(el, (dict, list))
                    else str(el)
                    for el in v
                )
                coerced[k] = {"texto": joined}
        else:
            coerced[k] = {"texto": str(v)}
    return coerced
